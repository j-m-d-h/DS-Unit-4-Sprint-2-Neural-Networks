diff --git a/module1-Intro-to-Neural-Networks/LS_DS_421_Intro_to_NN_Assignment.ipynb b/module1-Intro-to-Neural-Networks/LS_DS_421_Intro_to_NN_Assignment.ipynb
index af0d88b..c4cca8b 100644
--- a/module1-Intro-to-Neural-Networks/LS_DS_421_Intro_to_NN_Assignment.ipynb
+++ b/module1-Intro-to-Neural-Networks/LS_DS_421_Intro_to_NN_Assignment.ipynb
@@ -77,7 +77,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 2,
+   "execution_count": 1,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -343,9 +343,9 @@
    "version": "0.3.2"
   },
   "kernelspec": {
-   "display_name": "Python 3",
+   "display_name": "U4-S2-NNF",
    "language": "python",
-   "name": "python3"
+   "name": "u4-s2-nnf"
   },
   "language_info": {
    "codemirror_mode": {
@@ -357,9 +357,9 @@
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
-   "version": "3.7.3"
+   "version": "3.7.0"
   }
  },
  "nbformat": 4,
- "nbformat_minor": 2
+ "nbformat_minor": 4
 }
diff --git a/module2-backpropagation/LS_DS_422_Backprop_Assignment.ipynb b/module2-backpropagation/LS_DS_422_Backprop_Assignment.ipynb
index 307b203..8d32ee3 100644
--- a/module2-backpropagation/LS_DS_422_Backprop_Assignment.ipynb
+++ b/module2-backpropagation/LS_DS_422_Backprop_Assignment.ipynb
@@ -31,7 +31,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 1,
    "metadata": {
     "colab": {},
     "colab_type": "code",
@@ -39,7 +39,517 @@
    },
    "outputs": [],
    "source": [
-    "##### Your Code Here #####"
+    "import numpy as np\n",
+    "\n",
+    "X = np.array(([0,0,1],\n",
+    "              [0,1,1],\n",
+    "              [1,0,1],\n",
+    "              [0,1,0],\n",
+    "              [1,0,0],\n",
+    "              [1,1,1],\n",
+    "              [0,0,0]), dtype=float)\n",
+    "\n",
+    "y = np.array(([0],\n",
+    "              [1],\n",
+    "              [1],\n",
+    "              [1],\n",
+    "              [1],\n",
+    "              [0],\n",
+    "              [0]), dtype=float)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 19,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "class NeuralNetwork:\n",
+    "    def __init__(self):\n",
+    "\n",
+    "        self.inputs = 3\n",
+    "        self.hiddenNodes = 4\n",
+    "        self.outputNodes = 1\n",
+    "\n",
+    "        self.weights1 = np.random.rand(self.inputs, self.hiddenNodes)\n",
+    "       \n",
+    "        self.weights2 = np.random.rand(self.hiddenNodes, self.outputNodes)\n",
+    "        \n",
+    "    def sigmoid(self, s):\n",
+    "        return 1 / (1+np.exp(-s))\n",
+    "\n",
+    "    def sigmoidPrime(self, s):\n",
+    "        return s * (1 - s)\n",
+    "    \n",
+    "    def feed_forward(self, X):\n",
+    "        \n",
+    "        self.hidden_sum = np.dot(X, self.weights1)\n",
+    "        \n",
+    "        self.activated_hidden = self.sigmoid(self.hidden_sum)\n",
+    "        \n",
+    "        self.output_sum = np.dot(self.activated_hidden, self.weights2)\n",
+    "        \n",
+    "        self.activated_output = self.sigmoid(self.output_sum)\n",
+    "        \n",
+    "        return self.activated_output\n",
+    "    \n",
+    "    def back_prop(self, X, y, o):\n",
+    "\n",
+    "        self.o_error = y - o\n",
+    "        \n",
+    "        self.o_delta = self.o_error * self.sigmoidPrime(o)\n",
+    "        \n",
+    "        self.z2_error = self.o_delta.dot(self.weights2.T)\n",
+    "        \n",
+    "        self.z2_delta = self.z2_error * self.sigmoidPrime(self.activated_hidden)\n",
+    "        \n",
+    "        self.weights1 += X.T.dot(self.z2_delta)\n",
+    "\n",
+    "        self.weights2 += self.activated_hidden.T.dot(self.o_delta)\n",
+    "        \n",
+    "\n",
+    "    def train(self, X, y):\n",
+    "        o = self.feed_forward(X)\n",
+    "        self.back_prop(X,y,o)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 20,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "neural_net = NeuralNetwork()\n",
+    "\n",
+    "neural_net.train(X, y)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 24,
+   "metadata": {},
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "+---------EPOCH 1---------+\n",
+      "Input: \n",
+      " [[0. 0. 1.]\n",
+      " [0. 1. 1.]\n",
+      " [1. 0. 1.]\n",
+      " [0. 1. 0.]\n",
+      " [1. 0. 0.]\n",
+      " [1. 1. 1.]\n",
+      " [0. 0. 0.]]\n",
+      "Predicted Output: \n",
+      " [[0.00228424]\n",
+      " [0.98792048]\n",
+      " [0.98807781]\n",
+      " [0.9891835 ]\n",
+      " [0.98900968]\n",
+      " [0.00597504]\n",
+      " [0.02792256]]\n",
+      "Actual Output: \n",
+      " [[0.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [0.]\n",
+      " [0.]]\n",
+      "Loss: \n",
+      " 0.00019234654682418495\n",
+      "+---------EPOCH 2---------+\n",
+      "Input: \n",
+      " [[0. 0. 1.]\n",
+      " [0. 1. 1.]\n",
+      " [1. 0. 1.]\n",
+      " [0. 1. 0.]\n",
+      " [1. 0. 0.]\n",
+      " [1. 1. 1.]\n",
+      " [0. 0. 0.]]\n",
+      "Predicted Output: \n",
+      " [[0.0022841 ]\n",
+      " [0.98792111]\n",
+      " [0.98807843]\n",
+      " [0.98918404]\n",
+      " [0.98901023]\n",
+      " [0.00597462]\n",
+      " [0.02792116]]\n",
+      "Actual Output: \n",
+      " [[0.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [0.]\n",
+      " [0.]]\n",
+      "Loss: \n",
+      " 0.00019232686507185244\n",
+      "+---------EPOCH 3---------+\n",
+      "Input: \n",
+      " [[0. 0. 1.]\n",
+      " [0. 1. 1.]\n",
+      " [1. 0. 1.]\n",
+      " [0. 1. 0.]\n",
+      " [1. 0. 0.]\n",
+      " [1. 1. 1.]\n",
+      " [0. 0. 0.]]\n",
+      "Predicted Output: \n",
+      " [[0.00228395]\n",
+      " [0.98792175]\n",
+      " [0.98807905]\n",
+      " [0.98918457]\n",
+      " [0.98901078]\n",
+      " [0.00597421]\n",
+      " [0.02791977]]\n",
+      "Actual Output: \n",
+      " [[0.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [0.]\n",
+      " [0.]]\n",
+      "Loss: \n",
+      " 0.00019230718733502565\n",
+      "+---------EPOCH 4---------+\n",
+      "Input: \n",
+      " [[0. 0. 1.]\n",
+      " [0. 1. 1.]\n",
+      " [1. 0. 1.]\n",
+      " [0. 1. 0.]\n",
+      " [1. 0. 0.]\n",
+      " [1. 1. 1.]\n",
+      " [0. 0. 0.]]\n",
+      "Predicted Output: \n",
+      " [[0.0022838 ]\n",
+      " [0.98792238]\n",
+      " [0.98807968]\n",
+      " [0.98918511]\n",
+      " [0.98901134]\n",
+      " [0.00597379]\n",
+      " [0.02791837]]\n",
+      "Actual Output: \n",
+      " [[0.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [0.]\n",
+      " [0.]]\n",
+      "Loss: \n",
+      " 0.00019228751361247666\n",
+      "+---------EPOCH 5---------+\n",
+      "Input: \n",
+      " [[0. 0. 1.]\n",
+      " [0. 1. 1.]\n",
+      " [1. 0. 1.]\n",
+      " [0. 1. 0.]\n",
+      " [1. 0. 0.]\n",
+      " [1. 1. 1.]\n",
+      " [0. 0. 0.]]\n",
+      "Predicted Output: \n",
+      " [[0.00228365]\n",
+      " [0.98792302]\n",
+      " [0.9880803 ]\n",
+      " [0.98918565]\n",
+      " [0.98901189]\n",
+      " [0.00597338]\n",
+      " [0.02791697]]\n",
+      "Actual Output: \n",
+      " [[0.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [0.]\n",
+      " [0.]]\n",
+      "Loss: \n",
+      " 0.00019226784390298147\n",
+      "+---------EPOCH 6---------+\n",
+      "Input: \n",
+      " [[0. 0. 1.]\n",
+      " [0. 1. 1.]\n",
+      " [1. 0. 1.]\n",
+      " [0. 1. 0.]\n",
+      " [1. 0. 0.]\n",
+      " [1. 1. 1.]\n",
+      " [0. 0. 0.]]\n",
+      "Predicted Output: \n",
+      " [[0.00228351]\n",
+      " [0.98792366]\n",
+      " [0.98808092]\n",
+      " [0.98918619]\n",
+      " [0.98901244]\n",
+      " [0.00597297]\n",
+      " [0.02791557]]\n",
+      "Actual Output: \n",
+      " [[0.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [0.]\n",
+      " [0.]]\n",
+      "Loss: \n",
+      " 0.0001922481782053117\n",
+      "+---------EPOCH 7---------+\n",
+      "Input: \n",
+      " [[0. 0. 1.]\n",
+      " [0. 1. 1.]\n",
+      " [1. 0. 1.]\n",
+      " [0. 1. 0.]\n",
+      " [1. 0. 0.]\n",
+      " [1. 1. 1.]\n",
+      " [0. 0. 0.]]\n",
+      "Predicted Output: \n",
+      " [[0.00228336]\n",
+      " [0.98792429]\n",
+      " [0.98808154]\n",
+      " [0.98918673]\n",
+      " [0.989013  ]\n",
+      " [0.00597255]\n",
+      " [0.02791417]]\n",
+      "Actual Output: \n",
+      " [[0.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [0.]\n",
+      " [0.]]\n",
+      "Loss: \n",
+      " 0.00019222851651824196\n",
+      "+---------EPOCH 8---------+\n",
+      "Input: \n",
+      " [[0. 0. 1.]\n",
+      " [0. 1. 1.]\n",
+      " [1. 0. 1.]\n",
+      " [0. 1. 0.]\n",
+      " [1. 0. 0.]\n",
+      " [1. 1. 1.]\n",
+      " [0. 0. 0.]]\n",
+      "Predicted Output: \n",
+      " [[0.00228321]\n",
+      " [0.98792493]\n",
+      " [0.98808217]\n",
+      " [0.98918727]\n",
+      " [0.98901355]\n",
+      " [0.00597214]\n",
+      " [0.02791278]]\n",
+      "Actual Output: \n",
+      " [[0.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [0.]\n",
+      " [0.]]\n",
+      "Loss: \n",
+      " 0.00019220885884054675\n",
+      "+---------EPOCH 9---------+\n",
+      "Input: \n",
+      " [[0. 0. 1.]\n",
+      " [0. 1. 1.]\n",
+      " [1. 0. 1.]\n",
+      " [0. 1. 0.]\n",
+      " [1. 0. 0.]\n",
+      " [1. 1. 1.]\n",
+      " [0. 0. 0.]]\n",
+      "Predicted Output: \n",
+      " [[0.00228307]\n",
+      " [0.98792556]\n",
+      " [0.98808279]\n",
+      " [0.98918781]\n",
+      " [0.9890141 ]\n",
+      " [0.00597172]\n",
+      " [0.02791138]]\n",
+      "Actual Output: \n",
+      " [[0.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [0.]\n",
+      " [0.]]\n",
+      "Loss: \n",
+      " 0.00019218920517100014\n",
+      "+---------EPOCH 10---------+\n",
+      "Input: \n",
+      " [[0. 0. 1.]\n",
+      " [0. 1. 1.]\n",
+      " [1. 0. 1.]\n",
+      " [0. 1. 0.]\n",
+      " [1. 0. 0.]\n",
+      " [1. 1. 1.]\n",
+      " [0. 0. 0.]]\n",
+      "Predicted Output: \n",
+      " [[0.00228292]\n",
+      " [0.9879262 ]\n",
+      " [0.98808341]\n",
+      " [0.98918834]\n",
+      " [0.98901465]\n",
+      " [0.00597131]\n",
+      " [0.02790998]]\n",
+      "Actual Output: \n",
+      " [[0.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [0.]\n",
+      " [0.]]\n",
+      "Loss: \n",
+      " 0.00019216955550838005\n",
+      "+---------EPOCH 1000---------+\n",
+      "Input: \n",
+      " [[0. 0. 1.]\n",
+      " [0. 1. 1.]\n",
+      " [1. 0. 1.]\n",
+      " [0. 1. 0.]\n",
+      " [1. 0. 0.]\n",
+      " [1. 1. 1.]\n",
+      " [0. 0. 0.]]\n",
+      "Predicted Output: \n",
+      " [[0.00214827]\n",
+      " [0.9885101 ]\n",
+      " [0.98865575]\n",
+      " [0.98968452]\n",
+      " [0.98952374]\n",
+      " [0.00559406]\n",
+      " [0.02662201]]\n",
+      "Actual Output: \n",
+      " [[0.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [0.]\n",
+      " [0.]]\n",
+      "Loss: \n",
+      " 0.0001745015945010655\n",
+      "+---------EPOCH 2000---------+\n",
+      "Input: \n",
+      " [[0. 0. 1.]\n",
+      " [0. 1. 1.]\n",
+      " [1. 0. 1.]\n",
+      " [0. 1. 0.]\n",
+      " [1. 0. 0.]\n",
+      " [1. 1. 1.]\n",
+      " [0. 0. 0.]]\n",
+      "Predicted Output: \n",
+      " [[0.00203154]\n",
+      " [0.98902255]\n",
+      " [0.98915837]\n",
+      " [0.99012182]\n",
+      " [0.98997202]\n",
+      " [0.00526887]\n",
+      " [0.02548701]]\n",
+      "Actual Output: \n",
+      " [[0.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [0.]\n",
+      " [0.]]\n",
+      "Loss: \n",
+      " 0.00015966570704700352\n",
+      "+---------EPOCH 3000---------+\n",
+      "Input: \n",
+      " [[0. 0. 1.]\n",
+      " [0. 1. 1.]\n",
+      " [1. 0. 1.]\n",
+      " [0. 1. 0.]\n",
+      " [1. 0. 0.]\n",
+      " [1. 1. 1.]\n",
+      " [0. 0. 0.]]\n",
+      "Predicted Output: \n",
+      " [[0.00193011]\n",
+      " [0.98947286]\n",
+      " [0.98960027]\n",
+      " [0.99050752]\n",
+      " [0.99036711]\n",
+      " [0.00498775]\n",
+      " [0.02448604]]\n",
+      "Actual Output: \n",
+      " [[0.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [0.]\n",
+      " [0.]]\n",
+      "Loss: \n",
+      " 0.00014714913902624747\n",
+      "+---------EPOCH 4000---------+\n",
+      "Input: \n",
+      " [[0. 0. 1.]\n",
+      " [0. 1. 1.]\n",
+      " [1. 0. 1.]\n",
+      " [0. 1. 0.]\n",
+      " [1. 0. 0.]\n",
+      " [1. 1. 1.]\n",
+      " [0. 0. 0.]]\n",
+      "Predicted Output: \n",
+      " [[0.00184099]\n",
+      " [0.98987261]\n",
+      " [0.98999274]\n",
+      " [0.99085106]\n",
+      " [0.99071876]\n",
+      " [0.00474187]\n",
+      " [0.02359464]]\n",
+      "Actual Output: \n",
+      " [[0.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [0.]\n",
+      " [0.]]\n",
+      "Loss: \n",
+      " 0.00013644789681822435\n",
+      "+---------EPOCH 5000---------+\n",
+      "Input: \n",
+      " [[0. 0. 1.]\n",
+      " [0. 1. 1.]\n",
+      " [1. 0. 1.]\n",
+      " [0. 1. 0.]\n",
+      " [1. 0. 0.]\n",
+      " [1. 1. 1.]\n",
+      " [0. 0. 0.]]\n",
+      "Predicted Output: \n",
+      " [[0.00176194]\n",
+      " [0.99023057]\n",
+      " [0.99034434]\n",
+      " [0.9911596 ]\n",
+      " [0.9910344 ]\n",
+      " [0.00452469]\n",
+      " [0.02279415]]\n",
+      "Actual Output: \n",
+      " [[0.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [0.]\n",
+      " [0.]]\n",
+      "Loss: \n",
+      " 0.0001271940938834837\n"
+     ]
+    }
+   ],
+   "source": [
+    "for i in range(5000):\n",
+    "    if (i+1 in range(1, 11)) or ((i+1) % 1000 ==0):\n",
+    "        print('+' + '---' * 3 + f'EPOCH {i+1}' + '---'*3 + '+')\n",
+    "        print('Input: \\n', X)\n",
+    "        print('Predicted Output: \\n', str(neural_net.feed_forward(X)))\n",
+    "        print('Actual Output: \\n', y)\n",
+    "        print(\"Loss: \\n\", str(np.mean(np.square(y - neural_net.feed_forward(X)))))\n",
+    "    neural_net.train(X,y)"
    ]
   },
   {
@@ -242,9 +752,9 @@
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
-   "version": "3.7.3"
+   "version": "3.7.4"
   }
  },
  "nbformat": 4,
- "nbformat_minor": 2
+ "nbformat_minor": 4
 }
diff --git a/module2-backpropagation/LS_DS_422_Gradient_Descent_Backprop_Lecture.ipynb b/module2-backpropagation/LS_DS_422_Gradient_Descent_Backprop_Lecture.ipynb
index 8e64e1c..ac9372d 100644
--- a/module2-backpropagation/LS_DS_422_Gradient_Descent_Backprop_Lecture.ipynb
+++ b/module2-backpropagation/LS_DS_422_Gradient_Descent_Backprop_Lecture.ipynb
@@ -1486,7 +1486,7 @@
  ],
  "metadata": {
   "kernelspec": {
-   "display_name": "U4-S2-NNF (Python 3.7)",
+   "display_name": "U4-S2-NNF",
    "language": "python",
    "name": "u4-s2-nnf"
   },
@@ -1500,7 +1500,7 @@
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
-   "version": "3.7.3"
+   "version": "3.7.0"
   }
  },
  "nbformat": 4,
diff --git a/module3-Intro-to-Keras/LS_DS_423_Keras_Assignment.ipynb b/module3-Intro-to-Keras/LS_DS_423_Keras_Assignment.ipynb
index 2457723..c2606b3 100644
--- a/module3-Intro-to-Keras/LS_DS_423_Keras_Assignment.ipynb
+++ b/module3-Intro-to-Keras/LS_DS_423_Keras_Assignment.ipynb
@@ -32,7 +32,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 10,
    "metadata": {
     "colab": {},
     "colab_type": "code",
@@ -40,7 +40,395 @@
    },
    "outputs": [],
    "source": [
-    "##### Your Code Here #####"
+    "from tensorflow.keras.datasets import boston_housing\n",
+    "from tensorflow.keras.utils import to_categorical\n",
+    "from tensorflow.keras.models import Sequential\n",
+    "from tensorflow.keras.layers import Dense"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 15,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 30,
+   "metadata": {},
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "[[1.38516817e-02 0.00000000e+00 2.93439077e-01 ... 9.54545455e-01\n",
+      "  1.00000000e+00 4.93020806e-01]\n",
+      " [2.44672171e-04 8.25000000e-01 7.31795242e-02 ... 6.68181818e-01\n",
+      "  9.96170320e-01 8.19067685e-02]\n",
+      " [5.50509013e-02 0.00000000e+00 6.52487383e-01 ... 9.18181818e-01\n",
+      "  9.46132527e-01 8.58572557e-02]\n",
+      " ...\n",
+      " [3.89542372e-04 3.50000000e-01 2.18457102e-01 ... 7.68181818e-01\n",
+      "  9.12698413e-01 2.06215433e-01]\n",
+      " [2.41545492e-02 0.00000000e+00 7.05839942e-01 ... 6.68181818e-01\n",
+      "  6.59989922e-01 4.15854622e-01]\n",
+      " [1.61728642e-04 6.00000000e-01 1.05623648e-01 ... 7.09090909e-01\n",
+      "  9.49105568e-01 1.15354227e-01]]\n"
+     ]
+    }
+   ],
+   "source": [
+    "X_train = X_train / np.amax(X_train, axis=0)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 31,
+   "metadata": {},
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "1.0"
+      ]
+     },
+     "execution_count": 31,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": []
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 32,
+   "metadata": {},
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch 1/150\n",
+      "404/404 [==============================] - 0s 320us/sample - loss: 311.2546 - acc: 0.0000e+00\n",
+      "Epoch 2/150\n",
+      "404/404 [==============================] - 0s 62us/sample - loss: 307.6520 - acc: 0.0000e+00\n",
+      "Epoch 3/150\n",
+      "404/404 [==============================] - 0s 72us/sample - loss: 299.9498 - acc: 0.0000e+00\n",
+      "Epoch 4/150\n",
+      "404/404 [==============================] - 0s 73us/sample - loss: 286.7898 - acc: 0.0000e+00\n",
+      "Epoch 5/150\n",
+      "404/404 [==============================] - 0s 82us/sample - loss: 280.6785 - acc: 0.0000e+00\n",
+      "Epoch 6/150\n",
+      "404/404 [==============================] - 0s 74us/sample - loss: 274.9955 - acc: 0.0000e+00\n",
+      "Epoch 7/150\n",
+      "404/404 [==============================] - 0s 78us/sample - loss: 269.4262 - acc: 0.0000e+00\n",
+      "Epoch 8/150\n",
+      "404/404 [==============================] - 0s 77us/sample - loss: 267.5206 - acc: 0.0000e+00\n",
+      "Epoch 9/150\n",
+      "404/404 [==============================] - 0s 79us/sample - loss: 264.9829 - acc: 0.0000e+00\n",
+      "Epoch 10/150\n",
+      "404/404 [==============================] - 0s 81us/sample - loss: 261.0259 - acc: 0.0000e+00\n",
+      "Epoch 11/150\n",
+      "404/404 [==============================] - 0s 89us/sample - loss: 256.7242 - acc: 0.0000e+00\n",
+      "Epoch 12/150\n",
+      "404/404 [==============================] - 0s 89us/sample - loss: 252.4377 - acc: 0.0000e+00\n",
+      "Epoch 13/150\n",
+      "404/404 [==============================] - 0s 84us/sample - loss: 239.5965 - acc: 0.0000e+00\n",
+      "Epoch 14/150\n",
+      "404/404 [==============================] - 0s 89us/sample - loss: 225.5494 - acc: 0.0000e+00\n",
+      "Epoch 15/150\n",
+      "404/404 [==============================] - 0s 97us/sample - loss: 213.4369 - acc: 0.0000e+00\n",
+      "Epoch 16/150\n",
+      "404/404 [==============================] - 0s 94us/sample - loss: 194.7965 - acc: 0.0000e+00\n",
+      "Epoch 17/150\n",
+      "404/404 [==============================] - 0s 101us/sample - loss: 175.8713 - acc: 0.0000e+00\n",
+      "Epoch 18/150\n",
+      "404/404 [==============================] - 0s 94us/sample - loss: 162.1834 - acc: 0.0000e+00\n",
+      "Epoch 19/150\n",
+      "404/404 [==============================] - 0s 109us/sample - loss: 138.6354 - acc: 0.0000e+00\n",
+      "Epoch 20/150\n",
+      "404/404 [==============================] - 0s 81us/sample - loss: 110.9728 - acc: 0.0000e+00\n",
+      "Epoch 21/150\n",
+      "404/404 [==============================] - 0s 75us/sample - loss: 91.4688 - acc: 0.0000e+00\n",
+      "Epoch 22/150\n",
+      "404/404 [==============================] - 0s 77us/sample - loss: 74.5290 - acc: 0.0000e+00\n",
+      "Epoch 23/150\n",
+      "404/404 [==============================] - 0s 79us/sample - loss: 58.4907 - acc: 0.0000e+00\n",
+      "Epoch 24/150\n",
+      "404/404 [==============================] - 0s 79us/sample - loss: 38.2235 - acc: 0.0000e+00\n",
+      "Epoch 25/150\n",
+      "404/404 [==============================] - 0s 71us/sample - loss: 7.9538 - acc: 0.0000e+00\n",
+      "Epoch 26/150\n",
+      "404/404 [==============================] - 0s 74us/sample - loss: -9.6161 - acc: 0.0000e+00\n",
+      "Epoch 27/150\n",
+      "404/404 [==============================] - 0s 75us/sample - loss: -22.1051 - acc: 0.0000e+00\n",
+      "Epoch 28/150\n",
+      "404/404 [==============================] - 0s 80us/sample - loss: -36.5693 - acc: 0.0000e+00\n",
+      "Epoch 29/150\n",
+      "404/404 [==============================] - 0s 75us/sample - loss: -51.2666 - acc: 0.0000e+00\n",
+      "Epoch 30/150\n",
+      "404/404 [==============================] - 0s 95us/sample - loss: -63.1772 - acc: 0.0000e+00\n",
+      "Epoch 31/150\n",
+      "404/404 [==============================] - 0s 79us/sample - loss: -79.9133 - acc: 0.0000e+00\n",
+      "Epoch 32/150\n",
+      "404/404 [==============================] - 0s 91us/sample - loss: -97.0848 - acc: 0.0000e+00\n",
+      "Epoch 33/150\n",
+      "404/404 [==============================] - 0s 81us/sample - loss: -114.9622 - acc: 0.0000e+00\n",
+      "Epoch 34/150\n",
+      "404/404 [==============================] - 0s 91us/sample - loss: -129.6976 - acc: 0.0000e+00\n",
+      "Epoch 35/150\n",
+      "404/404 [==============================] - 0s 96us/sample - loss: -145.4799 - acc: 0.0000e+00\n",
+      "Epoch 36/150\n",
+      "404/404 [==============================] - 0s 91us/sample - loss: -169.0932 - acc: 0.0000e+00\n",
+      "Epoch 37/150\n",
+      "404/404 [==============================] - 0s 82us/sample - loss: -189.5318 - acc: 0.0000e+00\n",
+      "Epoch 38/150\n",
+      "404/404 [==============================] - 0s 81us/sample - loss: -211.3477 - acc: 0.0000e+00\n",
+      "Epoch 39/150\n",
+      "404/404 [==============================] - 0s 80us/sample - loss: -248.3458 - acc: 0.0000e+00\n",
+      "Epoch 40/150\n",
+      "404/404 [==============================] - 0s 78us/sample - loss: -270.6149 - acc: 0.0000e+00\n",
+      "Epoch 41/150\n",
+      "404/404 [==============================] - 0s 88us/sample - loss: -278.9053 - acc: 0.0000e+00\n",
+      "Epoch 42/150\n",
+      "404/404 [==============================] - 0s 88us/sample - loss: -286.9201 - acc: 0.0000e+00\n",
+      "Epoch 43/150\n",
+      "404/404 [==============================] - 0s 92us/sample - loss: -292.4355 - acc: 0.0000e+00\n",
+      "Epoch 44/150\n",
+      "404/404 [==============================] - 0s 84us/sample - loss: -298.1876 - acc: 0.0000e+00\n",
+      "Epoch 45/150\n",
+      "404/404 [==============================] - 0s 83us/sample - loss: -302.8983 - acc: 0.0000e+00\n",
+      "Epoch 46/150\n",
+      "404/404 [==============================] - 0s 84us/sample - loss: -309.3471 - acc: 0.0000e+00\n",
+      "Epoch 47/150\n",
+      "404/404 [==============================] - 0s 80us/sample - loss: -314.4464 - acc: 0.0000e+00\n",
+      "Epoch 48/150\n",
+      "404/404 [==============================] - 0s 84us/sample - loss: -315.5622 - acc: 0.0000e+00\n",
+      "Epoch 49/150\n",
+      "404/404 [==============================] - 0s 83us/sample - loss: -315.6718 - acc: 0.0000e+00\n",
+      "Epoch 50/150\n",
+      "404/404 [==============================] - 0s 88us/sample - loss: -316.4920 - acc: 0.0000e+00\n",
+      "Epoch 51/150\n",
+      "404/404 [==============================] - 0s 79us/sample - loss: -317.4937 - acc: 0.0000e+00\n",
+      "Epoch 52/150\n",
+      "404/404 [==============================] - 0s 84us/sample - loss: -318.0948 - acc: 0.0000e+00\n",
+      "Epoch 53/150\n",
+      "404/404 [==============================] - 0s 82us/sample - loss: -318.1733 - acc: 0.0000e+00\n",
+      "Epoch 54/150\n",
+      "404/404 [==============================] - 0s 86us/sample - loss: -318.2442 - acc: 0.0000e+00\n",
+      "Epoch 55/150\n",
+      "404/404 [==============================] - 0s 84us/sample - loss: -318.3199 - acc: 0.0000e+00\n",
+      "Epoch 56/150\n",
+      "404/404 [==============================] - 0s 91us/sample - loss: -318.5288 - acc: 0.0000e+00\n",
+      "Epoch 57/150\n",
+      "404/404 [==============================] - 0s 87us/sample - loss: -319.2313 - acc: 0.0000e+00\n",
+      "Epoch 58/150\n",
+      "404/404 [==============================] - 0s 81us/sample - loss: -319.6626 - acc: 0.0000e+00\n",
+      "Epoch 59/150\n",
+      "404/404 [==============================] - 0s 68us/sample - loss: -323.3065 - acc: 0.0000e+00\n",
+      "Epoch 60/150\n",
+      "404/404 [==============================] - ETA: 0s - loss: -363.1582 - acc: 0.0000e+ - 0s 62us/sample - loss: -326.7470 - acc: 0.0000e+00\n",
+      "Epoch 61/150\n",
+      "404/404 [==============================] - 0s 70us/sample - loss: -327.3436 - acc: 0.0000e+00\n",
+      "Epoch 62/150\n",
+      "404/404 [==============================] - 0s 72us/sample - loss: -327.3993 - acc: 0.0000e+00\n",
+      "Epoch 63/150\n",
+      "404/404 [==============================] - 0s 78us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 64/150\n",
+      "404/404 [==============================] - 0s 79us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 65/150\n",
+      "404/404 [==============================] - 0s 89us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 66/150\n",
+      "404/404 [==============================] - 0s 79us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 67/150\n",
+      "404/404 [==============================] - 0s 79us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 68/150\n",
+      "404/404 [==============================] - 0s 87us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 69/150\n",
+      "404/404 [==============================] - 0s 82us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 70/150\n",
+      "404/404 [==============================] - 0s 90us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 71/150\n",
+      "404/404 [==============================] - 0s 81us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 72/150\n",
+      "404/404 [==============================] - 0s 87us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 73/150\n",
+      "404/404 [==============================] - 0s 82us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 74/150\n",
+      "404/404 [==============================] - 0s 76us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 75/150\n",
+      "404/404 [==============================] - 0s 81us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 76/150\n",
+      "404/404 [==============================] - 0s 77us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 77/150\n",
+      "404/404 [==============================] - 0s 84us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 78/150\n",
+      "404/404 [==============================] - 0s 82us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 79/150\n",
+      "404/404 [==============================] - 0s 95us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 80/150\n",
+      "404/404 [==============================] - 0s 93us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 81/150\n",
+      "404/404 [==============================] - 0s 84us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 82/150\n",
+      "404/404 [==============================] - 0s 79us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 83/150\n",
+      "404/404 [==============================] - 0s 82us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 84/150\n",
+      "404/404 [==============================] - 0s 85us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 85/150\n",
+      "404/404 [==============================] - 0s 83us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 86/150\n",
+      "404/404 [==============================] - 0s 87us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 87/150\n",
+      "404/404 [==============================] - 0s 87us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 88/150\n",
+      "404/404 [==============================] - 0s 99us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 89/150\n",
+      "404/404 [==============================] - 0s 93us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 90/150\n",
+      "404/404 [==============================] - 0s 96us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 91/150\n",
+      "404/404 [==============================] - 0s 109us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 92/150\n",
+      "404/404 [==============================] - 0s 90us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 93/150\n",
+      "404/404 [==============================] - 0s 115us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 94/150\n",
+      "404/404 [==============================] - 0s 94us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 95/150\n",
+      "404/404 [==============================] - 0s 108us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 96/150\n",
+      "404/404 [==============================] - 0s 101us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 97/150\n",
+      "404/404 [==============================] - 0s 98us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 98/150\n",
+      "404/404 [==============================] - 0s 94us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 99/150\n",
+      "404/404 [==============================] - 0s 98us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 100/150\n",
+      "404/404 [==============================] - 0s 98us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 101/150\n",
+      "404/404 [==============================] - 0s 96us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 102/150\n",
+      "404/404 [==============================] - 0s 117us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 103/150\n",
+      "404/404 [==============================] - 0s 81us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 104/150\n",
+      "404/404 [==============================] - 0s 74us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 105/150\n",
+      "404/404 [==============================] - 0s 78us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 106/150\n",
+      "404/404 [==============================] - 0s 79us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 107/150\n",
+      "404/404 [==============================] - 0s 77us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 108/150\n",
+      "404/404 [==============================] - 0s 81us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 109/150\n",
+      "404/404 [==============================] - 0s 84us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 110/150\n",
+      "404/404 [==============================] - 0s 82us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 111/150\n",
+      "404/404 [==============================] - 0s 97us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 112/150\n",
+      "404/404 [==============================] - 0s 91us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 113/150\n",
+      "404/404 [==============================] - 0s 96us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 114/150\n",
+      "404/404 [==============================] - 0s 97us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 115/150\n",
+      "404/404 [==============================] - 0s 89us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 116/150\n",
+      "404/404 [==============================] - 0s 94us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 117/150\n",
+      "404/404 [==============================] - 0s 101us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 118/150\n",
+      "404/404 [==============================] - 0s 79us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 119/150\n",
+      "404/404 [==============================] - 0s 79us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 120/150\n",
+      "404/404 [==============================] - 0s 142us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 121/150\n",
+      "404/404 [==============================] - 0s 109us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 122/150\n",
+      "404/404 [==============================] - 0s 83us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 123/150\n",
+      "404/404 [==============================] - 0s 78us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 124/150\n",
+      "404/404 [==============================] - 0s 73us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 125/150\n",
+      "404/404 [==============================] - 0s 79us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 126/150\n",
+      "404/404 [==============================] - 0s 73us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 127/150\n",
+      "404/404 [==============================] - 0s 73us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 128/150\n",
+      "404/404 [==============================] - 0s 81us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 129/150\n",
+      "404/404 [==============================] - 0s 86us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 130/150\n",
+      "404/404 [==============================] - 0s 82us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 131/150\n",
+      "404/404 [==============================] - 0s 81us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 132/150\n",
+      "404/404 [==============================] - 0s 76us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 133/150\n",
+      "404/404 [==============================] - 0s 81us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 134/150\n",
+      "404/404 [==============================] - 0s 78us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 135/150\n",
+      "404/404 [==============================] - ETA: 0s - loss: -322.7646 - acc: 0.0000e+ - 0s 88us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 136/150\n",
+      "404/404 [==============================] - 0s 101us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 137/150\n",
+      "404/404 [==============================] - 0s 86us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 138/150\n",
+      "404/404 [==============================] - 0s 91us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 139/150\n",
+      "404/404 [==============================] - 0s 99us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 140/150\n",
+      "404/404 [==============================] - 0s 100us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 141/150\n",
+      "404/404 [==============================] - 0s 83us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 142/150\n",
+      "404/404 [==============================] - 0s 82us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 143/150\n",
+      "404/404 [==============================] - 0s 81us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 144/150\n",
+      "404/404 [==============================] - 0s 68us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 145/150\n",
+      "404/404 [==============================] - 0s 77us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 146/150\n",
+      "404/404 [==============================] - 0s 79us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 147/150\n",
+      "404/404 [==============================] - 0s 82us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 148/150\n",
+      "404/404 [==============================] - 0s 85us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 149/150\n",
+      "404/404 [==============================] - 0s 104us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 150/150\n",
+      "404/404 [==============================] - 0s 76us/sample - loss: -328.0554 - acc: 0.0000e+00\n"
+     ]
+    },
+    {
+     "data": {
+      "text/plain": [
+       "<tensorflow.python.keras.callbacks.History at 0x26b0ca1c5f8>"
+      ]
+     },
+     "execution_count": 32,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": [
+    "model = Sequential()\n",
+    "model.add(Dense(1, input_dim=13, activation=\"relu\"))\n",
+    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
+    "model.fit(X_train, y_train, epochs=150)"
    ]
   },
   {
@@ -96,9 +484,9 @@
    "version": "0.3.2"
   },
   "kernelspec": {
-   "display_name": "Python 3",
+   "display_name": "U4-S2-NNF",
    "language": "python",
-   "name": "python3"
+   "name": "u4-s2-nnf"
   },
   "language_info": {
    "codemirror_mode": {
@@ -110,9 +498,9 @@
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
-   "version": "3.7.3"
+   "version": "3.7.0"
   }
  },
  "nbformat": 4,
- "nbformat_minor": 2
+ "nbformat_minor": 4
 }
diff --git a/module3-Intro-to-Keras/LS_DS_423_Keras_Lecture.ipynb b/module3-Intro-to-Keras/LS_DS_423_Keras_Lecture.ipynb
index abc92b5..c7e6d4d 100644
--- a/module3-Intro-to-Keras/LS_DS_423_Keras_Lecture.ipynb
+++ b/module3-Intro-to-Keras/LS_DS_423_Keras_Lecture.ipynb
@@ -104,27 +104,39 @@
     "outputId": "12966e66-2297-4f82-85b3-c275a9c38563"
    },
    "outputs": [
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "WARNING: Logging before flag parsing goes to stderr.\n",
+      "W0122 16:35:22.440964 22032 deprecation.py:506] From C:\\ProgramData\\Anaconda3\\envs\\U4-S2-NNF\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
+      "Instructions for updating:\n",
+      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
+      "W0122 16:35:22.472933 22032 deprecation.py:323] From C:\\ProgramData\\Anaconda3\\envs\\U4-S2-NNF\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
+      "Instructions for updating:\n",
+      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
+     ]
+    },
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Train on 4 samples\n",
       "Epoch 1/5\n",
-      "4/4 [==============================] - 1s 184ms/sample - loss: 0.7531 - accuracy: 0.2500\n",
+      "4/4 [==============================] - 0s 15ms/sample - loss: 0.7489 - acc: 0.5000\n",
       "Epoch 2/5\n",
-      "4/4 [==============================] - 0s 1ms/sample - loss: 0.7527 - accuracy: 0.5000\n",
+      "4/4 [==============================] - 0s 244us/sample - loss: 0.7486 - acc: 0.7500\n",
       "Epoch 3/5\n",
-      "4/4 [==============================] - 0s 833us/sample - loss: 0.7524 - accuracy: 0.5000\n",
+      "4/4 [==============================] - 0s 241us/sample - loss: 0.7482 - acc: 0.7500\n",
       "Epoch 4/5\n",
-      "4/4 [==============================] - 0s 760us/sample - loss: 0.7520 - accuracy: 0.5000\n",
+      "4/4 [==============================] - 0s 241us/sample - loss: 0.7479 - acc: 0.7500\n",
       "Epoch 5/5\n",
-      "4/4 [==============================] - 0s 805us/sample - loss: 0.7517 - accuracy: 0.5000\n"
+      "4/4 [==============================] - 0s 243us/sample - loss: 0.7476 - acc: 0.7500\n"
      ]
     },
     {
      "data": {
       "text/plain": [
-       "<tensorflow.python.keras.callbacks.History at 0x7fb4cc4cdeb8>"
+       "<tensorflow.python.keras.callbacks.History at 0x1dc4604a128>"
       ]
      },
      "execution_count": 2,
@@ -160,8 +172,8 @@
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "4/1 [========================================================================================================================] - 0s 21ms/sample - loss: 0.7514 - accuracy: 0.5000\n",
-      "accuracy: 50.0\n"
+      "4/4 [==============================] - 0s 3ms/sample - loss: 0.7473 - acc: 0.7500\n",
+      "acc: 75.0\n"
      ]
     }
    ],
@@ -455,7 +467,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 8,
+   "execution_count": 4,
    "metadata": {
     "colab": {},
     "colab_type": "code",
@@ -483,7 +495,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 9,
+   "execution_count": 5,
    "metadata": {
     "colab": {},
     "colab_type": "code",
@@ -511,7 +523,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 17,
+   "execution_count": 6,
    "metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
@@ -2376,9 +2388,9 @@
    "version": "0.3.2"
   },
   "kernelspec": {
-   "display_name": "Python 3",
+   "display_name": "U4-S2-NNF",
    "language": "python",
-   "name": "python3"
+   "name": "u4-s2-nnf"
   },
   "language_info": {
    "codemirror_mode": {
@@ -2390,7 +2402,7 @@
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
-   "version": "3.6.8"
+   "version": "3.7.0"
   },
   "toc-autonumbering": false,
   "toc-showmarkdowntxt": false
diff --git a/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Assignment.ipynb b/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Assignment.ipynb
index ca65dc6..cf51878 100644
--- a/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Assignment.ipynb
+++ b/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Assignment.ipynb
@@ -91,9 +91,9 @@
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
-   "version": "3.7.3"
+   "version": "3.7.4"
   }
  },
  "nbformat": 4,
- "nbformat_minor": 2
+ "nbformat_minor": 4
 }
diff --git a/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Lecture.ipynb b/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Lecture.ipynb
index 4bb18e9..6076aea 100644
--- a/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Lecture.ipynb
+++ b/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Lecture.ipynb
@@ -42,7 +42,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 1,
+   "execution_count": 3,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -81,7 +81,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 1,
+   "execution_count": 4,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -106,7 +106,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 2,
+   "execution_count": 5,
    "metadata": {},
    "outputs": [
     {
@@ -170,7 +170,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 3,
+   "execution_count": 6,
    "metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
@@ -182,171 +182,27 @@
    },
    "outputs": [
     {
-     "name": "stdout",
+     "name": "stderr",
      "output_type": "stream",
      "text": [
-      "Train on 404 samples, validate on 102 samples\n",
-      "Epoch 1/75\n",
-      "404/404 [==============================] - 2s 4ms/sample - loss: 498.2045 - mse: 498.2046 - mae: 20.2543 - val_loss: 421.5039 - val_mse: 421.5038 - val_mae: 18.3349\n",
-      "Epoch 2/75\n",
-      "404/404 [==============================] - 0s 347us/sample - loss: 249.6985 - mse: 249.6985 - mae: 13.2672 - val_loss: 111.3743 - val_mse: 111.3743 - val_mae: 8.6210\n",
-      "Epoch 3/75\n",
-      "404/404 [==============================] - 0s 344us/sample - loss: 56.6755 - mse: 56.6755 - mae: 5.4817 - val_loss: 39.1997 - val_mse: 39.1997 - val_mae: 4.9872\n",
-      "Epoch 4/75\n",
-      "404/404 [==============================] - 0s 364us/sample - loss: 28.3243 - mse: 28.3243 - mae: 3.7054 - val_loss: 26.9866 - val_mse: 26.9866 - val_mae: 4.0796\n",
-      "Epoch 5/75\n",
-      "404/404 [==============================] - 0s 382us/sample - loss: 20.5281 - mse: 20.5281 - mae: 3.1209 - val_loss: 24.6172 - val_mse: 24.6172 - val_mae: 3.8052\n",
-      "Epoch 6/75\n",
-      "404/404 [==============================] - 0s 393us/sample - loss: 17.9283 - mse: 17.9283 - mae: 2.8665 - val_loss: 23.6524 - val_mse: 23.6524 - val_mae: 3.6746\n",
-      "Epoch 7/75\n",
-      "404/404 [==============================] - 0s 440us/sample - loss: 16.9179 - mse: 16.9179 - mae: 2.8781 - val_loss: 23.4620 - val_mse: 23.4620 - val_mae: 3.5778\n",
-      "Epoch 8/75\n",
-      "404/404 [==============================] - 0s 366us/sample - loss: 15.1579 - mse: 15.1579 - mae: 2.6440 - val_loss: 24.1374 - val_mse: 24.1374 - val_mae: 3.5929\n",
-      "Epoch 9/75\n",
-      "404/404 [==============================] - 0s 367us/sample - loss: 14.1717 - mse: 14.1717 - mae: 2.5937 - val_loss: 24.4829 - val_mse: 24.4829 - val_mae: 3.5639\n",
-      "Epoch 10/75\n",
-      "404/404 [==============================] - 0s 359us/sample - loss: 13.5002 - mse: 13.5002 - mae: 2.5633 - val_loss: 25.0170 - val_mse: 25.0170 - val_mae: 3.5601\n",
-      "Epoch 11/75\n",
-      "404/404 [==============================] - 0s 363us/sample - loss: 12.8641 - mse: 12.8641 - mae: 2.4963 - val_loss: 25.1162 - val_mse: 25.1162 - val_mae: 3.5449\n",
-      "Epoch 12/75\n",
-      "404/404 [==============================] - 0s 351us/sample - loss: 12.4033 - mse: 12.4033 - mae: 2.5224 - val_loss: 25.0382 - val_mse: 25.0382 - val_mae: 3.4858\n",
-      "Epoch 13/75\n",
-      "404/404 [==============================] - 0s 363us/sample - loss: 12.2653 - mse: 12.2653 - mae: 2.4637 - val_loss: 26.7274 - val_mse: 26.7274 - val_mae: 3.6054\n",
-      "Epoch 14/75\n",
-      "404/404 [==============================] - 0s 368us/sample - loss: 11.8249 - mse: 11.8249 - mae: 2.4648 - val_loss: 25.2347 - val_mse: 25.2347 - val_mae: 3.4602\n",
-      "Epoch 15/75\n",
-      "404/404 [==============================] - 0s 356us/sample - loss: 11.3965 - mse: 11.3965 - mae: 2.4134 - val_loss: 25.3070 - val_mse: 25.3070 - val_mae: 3.4305\n",
-      "Epoch 16/75\n",
-      "404/404 [==============================] - 0s 363us/sample - loss: 11.0982 - mse: 11.0982 - mae: 2.3616 - val_loss: 25.0599 - val_mse: 25.0599 - val_mae: 3.3784\n",
-      "Epoch 17/75\n",
-      "404/404 [==============================] - 0s 365us/sample - loss: 11.1969 - mse: 11.1969 - mae: 2.3806 - val_loss: 25.1976 - val_mse: 25.1976 - val_mae: 3.3732\n",
-      "Epoch 18/75\n",
-      "404/404 [==============================] - 0s 369us/sample - loss: 10.9278 - mse: 10.9278 - mae: 2.3653 - val_loss: 24.2875 - val_mse: 24.2875 - val_mae: 3.3114\n",
-      "Epoch 19/75\n",
-      "404/404 [==============================] - 0s 365us/sample - loss: 10.5854 - mse: 10.5854 - mae: 2.3170 - val_loss: 26.1450 - val_mse: 26.1450 - val_mae: 3.3971\n",
-      "Epoch 20/75\n",
-      "404/404 [==============================] - 0s 401us/sample - loss: 10.2546 - mse: 10.2546 - mae: 2.2813 - val_loss: 26.5278 - val_mse: 26.5278 - val_mae: 3.4465\n",
-      "Epoch 21/75\n",
-      "404/404 [==============================] - 0s 380us/sample - loss: 10.1321 - mse: 10.1321 - mae: 2.2866 - val_loss: 24.0363 - val_mse: 24.0363 - val_mae: 3.2792\n",
-      "Epoch 22/75\n",
-      "404/404 [==============================] - 0s 421us/sample - loss: 9.9169 - mse: 9.9169 - mae: 2.2907 - val_loss: 23.7310 - val_mse: 23.7310 - val_mae: 3.2334\n",
-      "Epoch 23/75\n",
-      "404/404 [==============================] - 0s 361us/sample - loss: 9.6588 - mse: 9.6588 - mae: 2.2284 - val_loss: 23.6472 - val_mse: 23.6472 - val_mae: 3.2013\n",
-      "Epoch 24/75\n",
-      "404/404 [==============================] - 0s 363us/sample - loss: 9.6887 - mse: 9.6887 - mae: 2.2468 - val_loss: 23.5379 - val_mse: 23.5379 - val_mae: 3.1921\n",
-      "Epoch 25/75\n",
-      "404/404 [==============================] - 0s 373us/sample - loss: 9.4049 - mse: 9.4049 - mae: 2.1999 - val_loss: 23.7713 - val_mse: 23.7713 - val_mae: 3.2273\n",
-      "Epoch 26/75\n",
-      "404/404 [==============================] - 0s 359us/sample - loss: 9.2304 - mse: 9.2304 - mae: 2.1946 - val_loss: 23.5093 - val_mse: 23.5093 - val_mae: 3.2072\n",
-      "Epoch 27/75\n",
-      "404/404 [==============================] - 0s 361us/sample - loss: 9.0493 - mse: 9.0493 - mae: 2.1528 - val_loss: 23.7969 - val_mse: 23.7969 - val_mae: 3.2005\n",
-      "Epoch 28/75\n",
-      "404/404 [==============================] - 0s 359us/sample - loss: 8.9363 - mse: 8.9363 - mae: 2.1475 - val_loss: 22.1030 - val_mse: 22.1030 - val_mae: 3.0707\n",
-      "Epoch 29/75\n",
-      "404/404 [==============================] - 0s 373us/sample - loss: 8.7834 - mse: 8.7834 - mae: 2.1231 - val_loss: 22.5153 - val_mse: 22.5153 - val_mae: 3.1532\n",
-      "Epoch 30/75\n",
-      "404/404 [==============================] - 0s 371us/sample - loss: 8.7925 - mse: 8.7925 - mae: 2.1531 - val_loss: 22.0449 - val_mse: 22.0449 - val_mae: 3.1245\n",
-      "Epoch 31/75\n",
-      "404/404 [==============================] - 0s 374us/sample - loss: 9.1879 - mse: 9.1879 - mae: 2.2029 - val_loss: 22.1780 - val_mse: 22.1780 - val_mae: 3.0623\n",
-      "Epoch 32/75\n",
-      "404/404 [==============================] - 0s 361us/sample - loss: 8.7136 - mse: 8.7136 - mae: 2.1164 - val_loss: 21.9815 - val_mse: 21.9815 - val_mae: 3.0969\n",
-      "Epoch 33/75\n",
-      "404/404 [==============================] - 0s 371us/sample - loss: 8.3018 - mse: 8.3018 - mae: 2.0639 - val_loss: 21.0477 - val_mse: 21.0477 - val_mae: 2.9645\n",
-      "Epoch 34/75\n",
-      "404/404 [==============================] - 0s 362us/sample - loss: 8.4156 - mse: 8.4156 - mae: 2.0970 - val_loss: 22.6659 - val_mse: 22.6659 - val_mae: 3.1235\n",
-      "Epoch 35/75\n",
-      "404/404 [==============================] - 0s 350us/sample - loss: 8.2938 - mse: 8.2938 - mae: 2.0567 - val_loss: 20.9574 - val_mse: 20.9574 - val_mae: 2.9746\n",
-      "Epoch 36/75\n",
-      "404/404 [==============================] - 0s 357us/sample - loss: 8.0515 - mse: 8.0515 - mae: 2.0591 - val_loss: 23.2063 - val_mse: 23.2063 - val_mae: 3.1980\n",
-      "Epoch 37/75\n",
-      "404/404 [==============================] - 0s 381us/sample - loss: 8.1403 - mse: 8.1403 - mae: 2.0584 - val_loss: 24.5238 - val_mse: 24.5237 - val_mae: 3.3531\n",
-      "Epoch 38/75\n",
-      "404/404 [==============================] - 0s 356us/sample - loss: 8.0043 - mse: 8.0043 - mae: 2.0776 - val_loss: 22.5424 - val_mse: 22.5424 - val_mae: 3.1494\n",
-      "Epoch 39/75\n",
-      "404/404 [==============================] - 0s 361us/sample - loss: 8.1182 - mse: 8.1182 - mae: 2.0683 - val_loss: 19.7576 - val_mse: 19.7576 - val_mae: 2.8799\n",
-      "Epoch 40/75\n",
-      "404/404 [==============================] - 0s 374us/sample - loss: 7.8578 - mse: 7.8578 - mae: 2.0131 - val_loss: 20.7728 - val_mse: 20.7728 - val_mae: 2.9499\n",
-      "Epoch 41/75\n",
-      "404/404 [==============================] - 0s 382us/sample - loss: 7.5711 - mse: 7.5711 - mae: 1.9896 - val_loss: 20.6170 - val_mse: 20.6170 - val_mae: 2.9936\n",
-      "Epoch 42/75\n",
-      "404/404 [==============================] - 0s 385us/sample - loss: 7.5822 - mse: 7.5822 - mae: 1.9683 - val_loss: 20.8541 - val_mse: 20.8541 - val_mae: 3.0054\n",
-      "Epoch 43/75\n",
-      "404/404 [==============================] - 0s 408us/sample - loss: 7.4533 - mse: 7.4533 - mae: 1.9645 - val_loss: 20.4473 - val_mse: 20.4473 - val_mae: 2.8861\n",
-      "Epoch 44/75\n",
-      "404/404 [==============================] - 0s 396us/sample - loss: 7.5226 - mse: 7.5226 - mae: 1.9509 - val_loss: 20.5193 - val_mse: 20.5193 - val_mae: 2.9619\n",
-      "Epoch 45/75\n",
-      "404/404 [==============================] - 0s 355us/sample - loss: 7.2819 - mse: 7.2819 - mae: 1.9350 - val_loss: 21.4862 - val_mse: 21.4862 - val_mae: 2.9908\n",
-      "Epoch 46/75\n",
-      "404/404 [==============================] - 0s 354us/sample - loss: 7.0130 - mse: 7.0130 - mae: 1.9152 - val_loss: 20.1577 - val_mse: 20.1577 - val_mae: 2.9370\n",
-      "Epoch 47/75\n",
-      "404/404 [==============================] - 0s 375us/sample - loss: 6.9431 - mse: 6.9431 - mae: 1.8819 - val_loss: 21.1210 - val_mse: 21.1210 - val_mae: 2.9746\n",
-      "Epoch 48/75\n",
-      "404/404 [==============================] - 0s 371us/sample - loss: 6.8982 - mse: 6.8982 - mae: 1.9037 - val_loss: 19.2999 - val_mse: 19.2999 - val_mae: 2.8638\n",
-      "Epoch 49/75\n",
-      "404/404 [==============================] - 0s 368us/sample - loss: 6.9521 - mse: 6.9521 - mae: 1.8862 - val_loss: 20.7825 - val_mse: 20.7825 - val_mae: 2.9369\n",
-      "Epoch 50/75\n",
-      "404/404 [==============================] - 0s 356us/sample - loss: 6.8718 - mse: 6.8718 - mae: 1.8889 - val_loss: 20.0288 - val_mse: 20.0288 - val_mae: 2.8915\n",
-      "Epoch 51/75\n",
-      "404/404 [==============================] - 0s 354us/sample - loss: 6.7111 - mse: 6.7111 - mae: 1.8702 - val_loss: 20.4913 - val_mse: 20.4913 - val_mae: 3.0116\n",
-      "Epoch 52/75\n",
-      "404/404 [==============================] - 0s 361us/sample - loss: 6.7492 - mse: 6.7492 - mae: 1.8482 - val_loss: 18.3008 - val_mse: 18.3008 - val_mae: 2.7362\n",
-      "Epoch 53/75\n",
-      "404/404 [==============================] - 0s 356us/sample - loss: 6.6262 - mse: 6.6262 - mae: 1.8395 - val_loss: 18.1885 - val_mse: 18.1885 - val_mae: 2.6920\n",
-      "Epoch 54/75\n",
-      "404/404 [==============================] - 0s 369us/sample - loss: 6.7148 - mse: 6.7148 - mae: 1.8611 - val_loss: 18.5764 - val_mse: 18.5764 - val_mae: 2.6977\n",
-      "Epoch 55/75\n",
-      "404/404 [==============================] - 0s 358us/sample - loss: 6.5425 - mse: 6.5425 - mae: 1.8522 - val_loss: 19.5772 - val_mse: 19.5772 - val_mae: 2.8326\n",
-      "Epoch 56/75\n",
-      "404/404 [==============================] - 0s 423us/sample - loss: 6.3349 - mse: 6.3349 - mae: 1.8175 - val_loss: 19.0932 - val_mse: 19.0932 - val_mae: 2.8260\n",
-      "Epoch 57/75\n",
-      "404/404 [==============================] - 0s 375us/sample - loss: 6.4253 - mse: 6.4253 - mae: 1.7972 - val_loss: 20.4036 - val_mse: 20.4036 - val_mae: 2.9258\n",
-      "Epoch 58/75\n",
-      "404/404 [==============================] - 0s 362us/sample - loss: 6.2897 - mse: 6.2897 - mae: 1.7785 - val_loss: 21.2845 - val_mse: 21.2845 - val_mae: 3.0715\n",
-      "Epoch 59/75\n",
-      "404/404 [==============================] - 0s 378us/sample - loss: 6.7839 - mse: 6.7839 - mae: 1.9027 - val_loss: 18.6853 - val_mse: 18.6853 - val_mae: 2.7709\n",
-      "Epoch 60/75\n",
-      "404/404 [==============================] - 0s 395us/sample - loss: 6.7178 - mse: 6.7178 - mae: 1.8871 - val_loss: 19.5394 - val_mse: 19.5394 - val_mae: 2.8101\n",
-      "Epoch 61/75\n",
-      "404/404 [==============================] - 0s 366us/sample - loss: 6.4152 - mse: 6.4152 - mae: 1.8175 - val_loss: 18.2377 - val_mse: 18.2377 - val_mae: 2.7450\n",
-      "Epoch 62/75\n",
-      "404/404 [==============================] - 0s 384us/sample - loss: 5.9727 - mse: 5.9727 - mae: 1.7630 - val_loss: 19.0252 - val_mse: 19.0252 - val_mae: 2.7960\n",
-      "Epoch 63/75\n",
-      "404/404 [==============================] - 0s 380us/sample - loss: 6.0973 - mse: 6.0973 - mae: 1.8071 - val_loss: 18.8069 - val_mse: 18.8069 - val_mae: 2.8894\n",
-      "Epoch 64/75\n",
-      "404/404 [==============================] - 0s 362us/sample - loss: 6.1074 - mse: 6.1074 - mae: 1.7978 - val_loss: 18.4702 - val_mse: 18.4702 - val_mae: 2.7851\n",
-      "Epoch 65/75\n",
-      "404/404 [==============================] - 0s 369us/sample - loss: 5.9329 - mse: 5.9329 - mae: 1.7545 - val_loss: 18.5321 - val_mse: 18.5321 - val_mae: 2.7933\n",
-      "Epoch 66/75\n",
-      "404/404 [==============================] - 0s 341us/sample - loss: 5.7473 - mse: 5.7473 - mae: 1.7211 - val_loss: 18.5536 - val_mse: 18.5536 - val_mae: 2.8010\n",
-      "Epoch 67/75\n",
-      "404/404 [==============================] - 0s 339us/sample - loss: 5.8866 - mse: 5.8866 - mae: 1.7224 - val_loss: 18.0067 - val_mse: 18.0067 - val_mae: 2.7054\n",
-      "Epoch 68/75\n",
-      "404/404 [==============================] - 0s 337us/sample - loss: 5.7885 - mse: 5.7885 - mae: 1.7391 - val_loss: 17.5502 - val_mse: 17.5502 - val_mae: 2.6767\n",
-      "Epoch 69/75\n",
-      "404/404 [==============================] - 0s 331us/sample - loss: 5.8809 - mse: 5.8809 - mae: 1.7542 - val_loss: 17.0280 - val_mse: 17.0280 - val_mae: 2.6404\n",
-      "Epoch 70/75\n",
-      "404/404 [==============================] - 0s 343us/sample - loss: 5.6028 - mse: 5.6028 - mae: 1.6972 - val_loss: 17.7188 - val_mse: 17.7188 - val_mae: 2.6979\n",
-      "Epoch 71/75\n",
-      "404/404 [==============================] - 0s 337us/sample - loss: 5.4361 - mse: 5.4361 - mae: 1.6741 - val_loss: 16.8852 - val_mse: 16.8852 - val_mae: 2.6126\n",
-      "Epoch 72/75\n",
-      "404/404 [==============================] - 0s 345us/sample - loss: 5.5608 - mse: 5.5608 - mae: 1.7252 - val_loss: 16.7483 - val_mse: 16.7483 - val_mae: 2.6063\n",
-      "Epoch 73/75\n",
-      "404/404 [==============================] - 0s 341us/sample - loss: 5.5022 - mse: 5.5022 - mae: 1.6912 - val_loss: 17.6786 - val_mse: 17.6786 - val_mae: 2.7316\n",
-      "Epoch 74/75\n",
-      "404/404 [==============================] - 0s 396us/sample - loss: 5.2794 - mse: 5.2794 - mae: 1.6478 - val_loss: 17.6115 - val_mse: 17.6115 - val_mae: 2.6773\n",
-      "Epoch 75/75\n",
-      "404/404 [==============================] - 0s 338us/sample - loss: 5.4796 - mse: 5.4796 - mae: 1.6876 - val_loss: 17.2835 - val_mse: 17.2835 - val_mae: 2.7126\n"
+      "WARNING: Logging before flag parsing goes to stderr.\n",
+      "W0123 13:31:56.599683 29748 deprecation.py:506] From C:\\ProgramData\\Anaconda3\\envs\\U4-S2-NNF\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
+      "Instructions for updating:\n",
+      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
      ]
     },
     {
-     "data": {
-      "text/plain": [
-       "<tensorflow.python.keras.callbacks.History at 0x7f36340c6b38>"
-      ]
-     },
-     "execution_count": 3,
-     "metadata": {},
-     "output_type": "execute_result"
+     "ename": "TypeError",
+     "evalue": "'NoneType' object is not iterable",
+     "output_type": "error",
+     "traceback": [
+      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
+      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
+      "\u001b[1;32m<ipython-input-6-ca2a1412e3bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m          )\n",
+      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\U4-S2-NNF\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m   def evaluate(self,\n",
+      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\U4-S2-NNF\\lib\\site-packages\\wandb\\keras\\__init__.py\u001b[0m in \u001b[0;36mnew_arrays\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[1;31m# TODO: these could be generators, why index 0?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mval_inputs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mval_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mval_inputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_targets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
+      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
+     ]
     }
    ],
    "source": [
@@ -449,7 +305,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 4,
+   "execution_count": 7,
    "metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
@@ -464,21 +320,24 @@
      "name": "stderr",
      "output_type": "stream",
      "text": [
-      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
-      "  warnings.warn(CV_WARNING, FutureWarning)\n"
+      "W0123 13:32:41.029052 29748 deprecation.py:323] From C:\\ProgramData\\Anaconda3\\envs\\U4-S2-NNF\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
+      "Instructions for updating:\n",
+      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
+      "C:\\ProgramData\\Anaconda3\\envs\\U4-S2-NNF\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
+      "  DeprecationWarning)\n"
      ]
     },
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Best: 0.65234375 using {'batch_size': 10, 'epochs': 20}\n",
-      "Means: 0.65234375, Stdev: 0.033298728782667764 with: {'batch_size': 10, 'epochs': 20}\n",
-      "Means: 0.6263020833333334, Stdev: 0.01813592223591682 with: {'batch_size': 20, 'epochs': 20}\n",
-      "Means: 0.6041666666666666, Stdev: 0.037782859709757574 with: {'batch_size': 40, 'epochs': 20}\n",
-      "Means: 0.5533854166666666, Stdev: 0.03210632293213009 with: {'batch_size': 60, 'epochs': 20}\n",
-      "Means: 0.61328125, Stdev: 0.024079742199097563 with: {'batch_size': 80, 'epochs': 20}\n",
-      "Means: 0.5611979166666666, Stdev: 0.038450060052691144 with: {'batch_size': 100, 'epochs': 20}\n"
+      "Best: 0.6432291716337204 using {'batch_size': 10, 'epochs': 20}\n",
+      "Means: 0.6432291716337204, Stdev: 0.03941603227192391 with: {'batch_size': 10, 'epochs': 20}\n",
+      "Means: 0.6250000174622983, Stdev: 0.05886315831701945 with: {'batch_size': 20, 'epochs': 20}\n",
+      "Means: 0.6250000071401397, Stdev: 0.04223050711440435 with: {'batch_size': 40, 'epochs': 20}\n",
+      "Means: 0.6432291700039059, Stdev: 0.06799620666076475 with: {'batch_size': 60, 'epochs': 20}\n",
+      "Means: 0.5989583501747499, Stdev: 0.08078131472004026 with: {'batch_size': 80, 'epochs': 20}\n",
+      "Means: 0.5494791712456694, Stdev: 0.048239581804148994 with: {'batch_size': 100, 'epochs': 20}\n"
      ]
     }
    ],
@@ -525,7 +384,7 @@
     "              'epochs': [20]}\n",
     "\n",
     "# Create Grid Search\n",
-    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
+    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, n_jobs=1)\n",
     "grid_result = grid.fit(X, Y)\n",
     "\n",
     "# Report Results\n",
@@ -551,7 +410,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 5,
+   "execution_count": null,
    "metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
@@ -561,22 +420,10 @@
     "id": "bAmxP3N7TmFh",
     "outputId": "3ddb08c4-51ac-4eaa-ff39-143397024544"
    },
-   "outputs": [
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "Best: 0.7044270833333334 using {'batch_size': 20, 'epochs': 200}\n",
-      "Means: 0.6666666666666666, Stdev: 0.028940248399600087 with: {'batch_size': 20, 'epochs': 20}\n",
-      "Means: 0.6588541666666666, Stdev: 0.028940248399600087 with: {'batch_size': 20, 'epochs': 40}\n",
-      "Means: 0.6848958333333334, Stdev: 0.03498705427745938 with: {'batch_size': 20, 'epochs': 60}\n",
-      "Means: 0.7044270833333334, Stdev: 0.018414239093399672 with: {'batch_size': 20, 'epochs': 200}\n"
-     ]
-    }
-   ],
+   "outputs": [],
    "source": [
     "# define the grid search parameters\n",
-    "param_grid = {'batch_size': [20],\n",
+    "param_grid = {'batch_size': [10],\n",
     "              'epochs': [20, 40, 60,200]}\n",
     "\n",
     "# Create Grid Search\n",
@@ -730,7 +577,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 6,
+   "execution_count": 9,
    "metadata": {},
    "outputs": [
     {
@@ -738,8 +585,8 @@
       "text/html": [
        "\n",
        "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
-       "                Project page: <a href=\"https://app.wandb.ai/lambda-ds7/boston\" target=\"_blank\">https://app.wandb.ai/lambda-ds7/boston</a><br/>\n",
-       "                Run page: <a href=\"https://app.wandb.ai/lambda-ds7/boston/runs/whw09rro\" target=\"_blank\">https://app.wandb.ai/lambda-ds7/boston/runs/whw09rro</a><br/>\n",
+       "                Project page: <a href=\"https://app.wandb.ai/ds8/ds9-boston\" target=\"_blank\">https://app.wandb.ai/ds8/ds9-boston</a><br/>\n",
+       "                Run page: <a href=\"https://app.wandb.ai/ds8/ds9-boston/runs/ctkbc6iz\" target=\"_blank\">https://app.wandb.ai/ds8/ds9-boston/runs/ctkbc6iz</a><br/>\n",
        "            "
       ],
       "text/plain": [
@@ -749,25 +596,33 @@
      "metadata": {},
      "output_type": "display_data"
     },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "E0123 13:35:09.350798 29748 jupyter.py:96] Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n"
+     ]
+    },
     {
      "data": {
       "text/plain": [
-       "W&B Run: https://app.wandb.ai/lambda-ds7/boston/runs/whw09rro"
+       "W&B Run: https://app.wandb.ai/ds8/ds9-boston/runs/ctkbc6iz"
       ]
      },
-     "execution_count": 6,
+     "execution_count": 9,
      "metadata": {},
      "output_type": "execute_result"
     }
    ],
    "source": [
     "import wandb\n",
-    "from wandb.keras import WandbCallback"
+    "from wandb.keras import WandbCallback\n",
+    "wandb.init(project=\"ds9-boston\", entity=\"ds8\")"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 8,
+   "execution_count": 11,
    "metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
@@ -783,8 +638,8 @@
       "text/html": [
        "\n",
        "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
-       "                Project page: <a href=\"https://app.wandb.ai/lambda-ds7/boston\" target=\"_blank\">https://app.wandb.ai/lambda-ds7/boston</a><br/>\n",
-       "                Run page: <a href=\"https://app.wandb.ai/lambda-ds7/boston/runs/kkgdtc31\" target=\"_blank\">https://app.wandb.ai/lambda-ds7/boston/runs/kkgdtc31</a><br/>\n",
+       "                Project page: <a href=\"https://app.wandb.ai/ds8/ds9-boston\" target=\"_blank\">https://app.wandb.ai/ds8/ds9-boston</a><br/>\n",
+       "                Run page: <a href=\"https://app.wandb.ai/ds8/ds9-boston/runs/f1dbcujb\" target=\"_blank\">https://app.wandb.ai/ds8/ds9-boston/runs/f1dbcujb</a><br/>\n",
        "            "
       ],
       "text/plain": [
@@ -794,126 +649,133 @@
      "metadata": {},
      "output_type": "display_data"
     },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "E0123 13:39:30.980396 29748 jupyter.py:96] Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n"
+     ]
+    },
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
       "Train on 270 samples, validate on 134 samples\n",
       "Epoch 1/50\n",
-      "270/270 [==============================] - 1s 3ms/sample - loss: 492.3539 - mse: 492.3539 - mae: 20.3197 - val_loss: 481.5445 - val_mse: 481.5445 - val_mae: 19.6138\n",
+      "270/270 [==============================] - 3s 10ms/sample - loss: 493.8940 - mean_squared_error: 493.8940 - mean_absolute_error: 20.4195 - val_loss: 477.3046 - val_mean_squared_error: 477.3046 - val_mean_absolute_error: 19.6141\n",
       "Epoch 2/50\n",
-      "270/270 [==============================] - 0s 591us/sample - loss: 239.4999 - mse: 239.4999 - mae: 12.8064 - val_loss: 113.8561 - val_mse: 113.8561 - val_mae: 8.2962\n",
+      "270/270 [==============================] - 0s 771us/sample - loss: 240.6677 - mean_squared_error: 240.6677 - mean_absolute_error: 12.9338 - val_loss: 109.7719 - val_mean_squared_error: 109.7719 - val_mean_absolute_error: 7.8025\n",
       "Epoch 3/50\n",
-      "270/270 [==============================] - 0s 618us/sample - loss: 56.2921 - mse: 56.2921 - mae: 5.8988 - val_loss: 62.7912 - val_mse: 62.7912 - val_mae: 5.6465\n",
+      "270/270 [==============================] - 0s 890us/sample - loss: 55.2241 - mean_squared_error: 55.2241 - mean_absolute_error: 5.5275 - val_loss: 63.8766 - val_mean_squared_error: 63.8766 - val_mean_absolute_error: 5.5448\n",
       "Epoch 4/50\n",
-      "270/270 [==============================] - 0s 613us/sample - loss: 29.4994 - mse: 29.4994 - mae: 3.9653 - val_loss: 37.9256 - val_mse: 37.9256 - val_mae: 4.1730\n",
+      "270/270 [==============================] - 0s 950us/sample - loss: 28.4961 - mean_squared_error: 28.4961 - mean_absolute_error: 3.8607 - val_loss: 41.4660 - val_mean_squared_error: 41.4660 - val_mean_absolute_error: 4.1364\n",
       "Epoch 5/50\n",
-      "270/270 [==============================] - 0s 608us/sample - loss: 20.6919 - mse: 20.6919 - mae: 3.3022 - val_loss: 31.7489 - val_mse: 31.7489 - val_mae: 3.7113\n",
+      "270/270 [==============================] - 0s 950us/sample - loss: 20.4916 - mean_squared_error: 20.4916 - mean_absolute_error: 3.1645 - val_loss: 34.4274 - val_mean_squared_error: 34.4274 - val_mean_absolute_error: 3.6639\n",
       "Epoch 6/50\n",
-      "270/270 [==============================] - 0s 602us/sample - loss: 17.2701 - mse: 17.2701 - mae: 3.0291 - val_loss: 27.3921 - val_mse: 27.3921 - val_mae: 3.4958\n",
+      "270/270 [==============================] - 0s 818us/sample - loss: 17.3112 - mean_squared_error: 17.3112 - mean_absolute_error: 2.9298 - val_loss: 31.9503 - val_mean_squared_error: 31.9503 - val_mean_absolute_error: 3.4603\n",
       "Epoch 7/50\n",
-      "270/270 [==============================] - 0s 671us/sample - loss: 15.5172 - mse: 15.5172 - mae: 2.8537 - val_loss: 25.3208 - val_mse: 25.3208 - val_mae: 3.3650\n",
+      "270/270 [==============================] - 0s 903us/sample - loss: 15.4195 - mean_squared_error: 15.4195 - mean_absolute_error: 2.8226 - val_loss: 27.3923 - val_mean_squared_error: 27.3923 - val_mean_absolute_error: 3.2832\n",
       "Epoch 8/50\n",
-      "270/270 [==============================] - 0s 661us/sample - loss: 13.7548 - mse: 13.7548 - mae: 2.7089 - val_loss: 23.8920 - val_mse: 23.8920 - val_mae: 3.2746\n",
+      "270/270 [==============================] - 0s 862us/sample - loss: 14.0896 - mean_squared_error: 14.0896 - mean_absolute_error: 2.7080 - val_loss: 26.7905 - val_mean_squared_error: 26.7905 - val_mean_absolute_error: 3.2033\n",
       "Epoch 9/50\n",
-      "270/270 [==============================] - 0s 606us/sample - loss: 12.3745 - mse: 12.3745 - mae: 2.5662 - val_loss: 22.1294 - val_mse: 22.1294 - val_mae: 3.1509\n",
+      "270/270 [==============================] - 0s 989us/sample - loss: 13.0160 - mean_squared_error: 13.0160 - mean_absolute_error: 2.6041 - val_loss: 23.6692 - val_mean_squared_error: 23.6692 - val_mean_absolute_error: 2.9825\n",
       "Epoch 10/50\n",
-      "270/270 [==============================] - 0s 614us/sample - loss: 11.2424 - mse: 11.2424 - mae: 2.4804 - val_loss: 20.5718 - val_mse: 20.5718 - val_mae: 3.0461\n",
+      "270/270 [==============================] - ETA: 0s - loss: 10.4319 - mean_squared_error: 10.4319 - mean_absolute_error: 2.41 - 0s 921us/sample - loss: 12.4798 - mean_squared_error: 12.4798 - mean_absolute_error: 2.5860 - val_loss: 22.3664 - val_mean_squared_error: 22.3664 - val_mean_absolute_error: 2.8995\n",
       "Epoch 11/50\n",
-      "270/270 [==============================] - 0s 605us/sample - loss: 10.6098 - mse: 10.6098 - mae: 2.4178 - val_loss: 20.3467 - val_mse: 20.3467 - val_mae: 3.0251\n",
+      "270/270 [==============================] - 0s 979us/sample - loss: 11.6495 - mean_squared_error: 11.6495 - mean_absolute_error: 2.4837 - val_loss: 21.5430 - val_mean_squared_error: 21.5430 - val_mean_absolute_error: 2.8736\n",
       "Epoch 12/50\n",
-      "270/270 [==============================] - 0s 576us/sample - loss: 10.0011 - mse: 10.0011 - mae: 2.3257 - val_loss: 18.4283 - val_mse: 18.4283 - val_mae: 2.8938\n",
+      "270/270 [==============================] - 0s 594us/sample - loss: 11.0023 - mean_squared_error: 11.0023 - mean_absolute_error: 2.4399 - val_loss: 21.7717 - val_mean_squared_error: 21.7717 - val_mean_absolute_error: 2.8785\n",
       "Epoch 13/50\n",
-      "270/270 [==============================] - 0s 666us/sample - loss: 9.1287 - mse: 9.1287 - mae: 2.2384 - val_loss: 18.2024 - val_mse: 18.2024 - val_mae: 2.9116\n",
+      "270/270 [==============================] - 0s 1ms/sample - loss: 10.5997 - mean_squared_error: 10.5997 - mean_absolute_error: 2.4560 - val_loss: 20.1542 - val_mean_squared_error: 20.1542 - val_mean_absolute_error: 2.7878\n",
       "Epoch 14/50\n",
-      "270/270 [==============================] - 0s 603us/sample - loss: 8.6211 - mse: 8.6211 - mae: 2.1980 - val_loss: 17.4749 - val_mse: 17.4749 - val_mae: 2.8290\n",
+      "270/270 [==============================] - 0s 980us/sample - loss: 10.0790 - mean_squared_error: 10.0790 - mean_absolute_error: 2.3498 - val_loss: 19.3464 - val_mean_squared_error: 19.3464 - val_mean_absolute_error: 2.8086\n",
       "Epoch 15/50\n",
-      "270/270 [==============================] - 0s 463us/sample - loss: 8.4558 - mse: 8.4558 - mae: 2.2087 - val_loss: 17.7878 - val_mse: 17.7878 - val_mae: 2.8516\n",
+      "270/270 [==============================] - 0s 909us/sample - loss: 9.2923 - mean_squared_error: 9.2923 - mean_absolute_error: 2.2524 - val_loss: 17.8887 - val_mean_squared_error: 17.8887 - val_mean_absolute_error: 2.7123\n",
       "Epoch 16/50\n",
-      "270/270 [==============================] - 0s 626us/sample - loss: 8.3626 - mse: 8.3626 - mae: 2.2031 - val_loss: 16.7101 - val_mse: 16.7101 - val_mae: 2.7820\n",
+      "270/270 [==============================] - 0s 1ms/sample - loss: 9.1706 - mean_squared_error: 9.1706 - mean_absolute_error: 2.2442 - val_loss: 17.3296 - val_mean_squared_error: 17.3296 - val_mean_absolute_error: 2.6656\n",
       "Epoch 17/50\n",
-      "270/270 [==============================] - 0s 607us/sample - loss: 7.9180 - mse: 7.9180 - mae: 2.1265 - val_loss: 16.6064 - val_mse: 16.6064 - val_mae: 2.7419\n",
+      "270/270 [==============================] - 0s 910us/sample - loss: 8.6335 - mean_squared_error: 8.6335 - mean_absolute_error: 2.2005 - val_loss: 17.3196 - val_mean_squared_error: 17.3196 - val_mean_absolute_error: 2.6946\n",
       "Epoch 18/50\n",
-      "270/270 [==============================] - 0s 479us/sample - loss: 7.5552 - mse: 7.5552 - mae: 2.0235 - val_loss: 17.2872 - val_mse: 17.2872 - val_mae: 2.8539\n",
+      "270/270 [==============================] - 0s 822us/sample - loss: 8.3288 - mean_squared_error: 8.3288 - mean_absolute_error: 2.1958 - val_loss: 16.9733 - val_mean_squared_error: 16.9733 - val_mean_absolute_error: 2.6816\n",
       "Epoch 19/50\n",
-      "270/270 [==============================] - 0s 616us/sample - loss: 7.0971 - mse: 7.0971 - mae: 2.0038 - val_loss: 16.5110 - val_mse: 16.5110 - val_mae: 2.8042\n",
+      "270/270 [==============================] - 0s 1ms/sample - loss: 7.8309 - mean_squared_error: 7.8309 - mean_absolute_error: 2.0968 - val_loss: 15.8521 - val_mean_squared_error: 15.8521 - val_mean_absolute_error: 2.6402\n",
       "Epoch 20/50\n",
-      "270/270 [==============================] - 0s 606us/sample - loss: 6.7068 - mse: 6.7068 - mae: 1.9539 - val_loss: 15.5886 - val_mse: 15.5886 - val_mae: 2.7048\n",
+      "270/270 [==============================] - 0s 666us/sample - loss: 8.0360 - mean_squared_error: 8.0360 - mean_absolute_error: 2.1393 - val_loss: 15.8692 - val_mean_squared_error: 15.8692 - val_mean_absolute_error: 2.6633\n",
       "Epoch 21/50\n",
-      "270/270 [==============================] - 0s 461us/sample - loss: 6.8542 - mse: 6.8542 - mae: 1.9979 - val_loss: 17.2378 - val_mse: 17.2378 - val_mae: 2.8853\n",
+      "270/270 [==============================] - 0s 907us/sample - loss: 7.4566 - mean_squared_error: 7.4566 - mean_absolute_error: 2.0696 - val_loss: 15.5674 - val_mean_squared_error: 15.5674 - val_mean_absolute_error: 2.6443\n",
       "Epoch 22/50\n",
-      "270/270 [==============================] - 0s 474us/sample - loss: 6.5719 - mse: 6.5719 - mae: 1.9312 - val_loss: 16.3043 - val_mse: 16.3043 - val_mae: 2.7756\n",
+      "270/270 [==============================] - 0s 630us/sample - loss: 7.2754 - mean_squared_error: 7.2754 - mean_absolute_error: 2.0436 - val_loss: 15.6940 - val_mean_squared_error: 15.6940 - val_mean_absolute_error: 2.6606\n",
       "Epoch 23/50\n",
-      "270/270 [==============================] - 0s 478us/sample - loss: 6.6161 - mse: 6.6161 - mae: 1.9572 - val_loss: 15.7992 - val_mse: 15.7992 - val_mae: 2.7219\n",
+      "270/270 [==============================] - 0s 659us/sample - loss: 6.9954 - mean_squared_error: 6.9954 - mean_absolute_error: 2.0051 - val_loss: 15.7101 - val_mean_squared_error: 15.7101 - val_mean_absolute_error: 2.6737\n",
       "Epoch 24/50\n",
-      "270/270 [==============================] - 0s 491us/sample - loss: 7.1269 - mse: 7.1269 - mae: 2.0137 - val_loss: 16.5402 - val_mse: 16.5402 - val_mae: 2.8005\n",
+      "270/270 [==============================] - 0s 902us/sample - loss: 7.4341 - mean_squared_error: 7.4341 - mean_absolute_error: 2.1136 - val_loss: 15.3135 - val_mean_squared_error: 15.3135 - val_mean_absolute_error: 2.6357\n",
       "Epoch 25/50\n",
-      "270/270 [==============================] - 0s 479us/sample - loss: 6.3382 - mse: 6.3382 - mae: 1.8540 - val_loss: 16.5034 - val_mse: 16.5034 - val_mae: 2.7864\n",
+      "270/270 [==============================] - 0s 1ms/sample - loss: 6.8092 - mean_squared_error: 6.8092 - mean_absolute_error: 1.9493 - val_loss: 15.2583 - val_mean_squared_error: 15.2583 - val_mean_absolute_error: 2.5772\n",
       "Epoch 26/50\n",
-      "270/270 [==============================] - 0s 488us/sample - loss: 5.9442 - mse: 5.9442 - mae: 1.8251 - val_loss: 15.6558 - val_mse: 15.6558 - val_mae: 2.7102\n",
+      "270/270 [==============================] - 0s 664us/sample - loss: 6.6624 - mean_squared_error: 6.6624 - mean_absolute_error: 1.9557 - val_loss: 15.7643 - val_mean_squared_error: 15.7643 - val_mean_absolute_error: 2.7206\n",
       "Epoch 27/50\n",
-      "270/270 [==============================] - 0s 604us/sample - loss: 5.5832 - mse: 5.5832 - mae: 1.7432 - val_loss: 15.3021 - val_mse: 15.3021 - val_mae: 2.6862\n",
+      "270/270 [==============================] - 0s 930us/sample - loss: 6.3992 - mean_squared_error: 6.3992 - mean_absolute_error: 1.9530 - val_loss: 15.2317 - val_mean_squared_error: 15.2317 - val_mean_absolute_error: 2.5774\n",
       "Epoch 28/50\n",
-      "270/270 [==============================] - 0s 436us/sample - loss: 5.4530 - mse: 5.4530 - mae: 1.7354 - val_loss: 15.4570 - val_mse: 15.4570 - val_mae: 2.6846\n",
+      "270/270 [==============================] - 0s 958us/sample - loss: 6.2930 - mean_squared_error: 6.2931 - mean_absolute_error: 1.8750 - val_loss: 14.9632 - val_mean_squared_error: 14.9632 - val_mean_absolute_error: 2.5158\n",
       "Epoch 29/50\n",
-      "270/270 [==============================] - 0s 441us/sample - loss: 5.3070 - mse: 5.3070 - mae: 1.7079 - val_loss: 15.8510 - val_mse: 15.8510 - val_mae: 2.7644\n",
+      "270/270 [==============================] - 0s 617us/sample - loss: 6.4084 - mean_squared_error: 6.4084 - mean_absolute_error: 1.8838 - val_loss: 15.0978 - val_mean_squared_error: 15.0978 - val_mean_absolute_error: 2.5785\n",
       "Epoch 30/50\n",
-      "270/270 [==============================] - 0s 477us/sample - loss: 5.4157 - mse: 5.4157 - mae: 1.7321 - val_loss: 15.9160 - val_mse: 15.9160 - val_mae: 2.7134\n",
+      "270/270 [==============================] - 0s 789us/sample - loss: 6.0627 - mean_squared_error: 6.0627 - mean_absolute_error: 1.8328 - val_loss: 14.8470 - val_mean_squared_error: 14.8470 - val_mean_absolute_error: 2.5660\n",
       "Epoch 31/50\n",
-      "270/270 [==============================] - 0s 452us/sample - loss: 5.2639 - mse: 5.2639 - mae: 1.6981 - val_loss: 15.3554 - val_mse: 15.3554 - val_mae: 2.6662\n",
+      "270/270 [==============================] - 0s 648us/sample - loss: 5.9582 - mean_squared_error: 5.9582 - mean_absolute_error: 1.8329 - val_loss: 15.5582 - val_mean_squared_error: 15.5582 - val_mean_absolute_error: 2.6379\n",
       "Epoch 32/50\n",
-      "270/270 [==============================] - 0s 475us/sample - loss: 5.7687 - mse: 5.7687 - mae: 1.8045 - val_loss: 15.7151 - val_mse: 15.7151 - val_mae: 2.6867\n",
+      "270/270 [==============================] - 0s 816us/sample - loss: 5.6998 - mean_squared_error: 5.6998 - mean_absolute_error: 1.7471 - val_loss: 14.4326 - val_mean_squared_error: 14.4326 - val_mean_absolute_error: 2.4840\n",
       "Epoch 33/50\n",
-      "270/270 [==============================] - 0s 462us/sample - loss: 5.5210 - mse: 5.5210 - mae: 1.7367 - val_loss: 15.4227 - val_mse: 15.4227 - val_mae: 2.6561\n",
+      "270/270 [==============================] - 0s 631us/sample - loss: 5.5009 - mean_squared_error: 5.5009 - mean_absolute_error: 1.7414 - val_loss: 15.0128 - val_mean_squared_error: 15.0128 - val_mean_absolute_error: 2.6083\n",
       "Epoch 34/50\n",
-      "270/270 [==============================] - 0s 474us/sample - loss: 5.5663 - mse: 5.5663 - mae: 1.7294 - val_loss: 15.3376 - val_mse: 15.3376 - val_mae: 2.6991\n",
+      "270/270 [==============================] - 0s 822us/sample - loss: 5.7764 - mean_squared_error: 5.7764 - mean_absolute_error: 1.7803 - val_loss: 14.2340 - val_mean_squared_error: 14.2340 - val_mean_absolute_error: 2.4877\n",
       "Epoch 35/50\n",
-      "270/270 [==============================] - 0s 626us/sample - loss: 5.0063 - mse: 5.0063 - mae: 1.6196 - val_loss: 15.2642 - val_mse: 15.2642 - val_mae: 2.6796\n",
+      "270/270 [==============================] - 0s 567us/sample - loss: 5.4853 - mean_squared_error: 5.4853 - mean_absolute_error: 1.7457 - val_loss: 14.7636 - val_mean_squared_error: 14.7636 - val_mean_absolute_error: 2.5905\n",
       "Epoch 36/50\n",
-      "270/270 [==============================] - 0s 459us/sample - loss: 4.7251 - mse: 4.7251 - mae: 1.5727 - val_loss: 15.4858 - val_mse: 15.4858 - val_mae: 2.7288\n",
+      "270/270 [==============================] - 0s 768us/sample - loss: 5.2506 - mean_squared_error: 5.2506 - mean_absolute_error: 1.7286 - val_loss: 14.1197 - val_mean_squared_error: 14.1197 - val_mean_absolute_error: 2.4953\n",
       "Epoch 37/50\n",
-      "270/270 [==============================] - 0s 604us/sample - loss: 4.6394 - mse: 4.6394 - mae: 1.5854 - val_loss: 15.1139 - val_mse: 15.1139 - val_mae: 2.6305\n",
+      "270/270 [==============================] - 0s 922us/sample - loss: 5.1762 - mean_squared_error: 5.1762 - mean_absolute_error: 1.6553 - val_loss: 14.1165 - val_mean_squared_error: 14.1165 - val_mean_absolute_error: 2.4918\n",
       "Epoch 38/50\n",
-      "270/270 [==============================] - 0s 592us/sample - loss: 4.5669 - mse: 4.5669 - mae: 1.5548 - val_loss: 14.9898 - val_mse: 14.9898 - val_mae: 2.6340\n",
+      "270/270 [==============================] - 0s 983us/sample - loss: 5.2728 - mean_squared_error: 5.2728 - mean_absolute_error: 1.6770 - val_loss: 14.0334 - val_mean_squared_error: 14.0334 - val_mean_absolute_error: 2.4714\n",
       "Epoch 39/50\n",
-      "270/270 [==============================] - 0s 458us/sample - loss: 4.4480 - mse: 4.4480 - mae: 1.5334 - val_loss: 15.6389 - val_mse: 15.6389 - val_mae: 2.7337\n",
+      "270/270 [==============================] - 0s 629us/sample - loss: 5.5355 - mean_squared_error: 5.5355 - mean_absolute_error: 1.7412 - val_loss: 14.1812 - val_mean_squared_error: 14.1812 - val_mean_absolute_error: 2.4753\n",
       "Epoch 40/50\n",
-      "270/270 [==============================] - 0s 455us/sample - loss: 4.4119 - mse: 4.4119 - mae: 1.5426 - val_loss: 15.0723 - val_mse: 15.0723 - val_mae: 2.6709\n",
+      "270/270 [==============================] - 0s 595us/sample - loss: 5.3025 - mean_squared_error: 5.3025 - mean_absolute_error: 1.6774 - val_loss: 14.4741 - val_mean_squared_error: 14.4741 - val_mean_absolute_error: 2.4635\n",
       "Epoch 41/50\n",
-      "270/270 [==============================] - 0s 473us/sample - loss: 4.0797 - mse: 4.0797 - mae: 1.4725 - val_loss: 15.4706 - val_mse: 15.4706 - val_mae: 2.6707\n",
+      "270/270 [==============================] - 0s 722us/sample - loss: 5.2436 - mean_squared_error: 5.2436 - mean_absolute_error: 1.7034 - val_loss: 14.2060 - val_mean_squared_error: 14.2060 - val_mean_absolute_error: 2.4683\n",
       "Epoch 42/50\n",
-      "270/270 [==============================] - 0s 449us/sample - loss: 4.0619 - mse: 4.0619 - mae: 1.4692 - val_loss: 15.2423 - val_mse: 15.2423 - val_mae: 2.6165\n",
+      "270/270 [==============================] - 0s 600us/sample - loss: 4.7837 - mean_squared_error: 4.7837 - mean_absolute_error: 1.6030 - val_loss: 14.3907 - val_mean_squared_error: 14.3907 - val_mean_absolute_error: 2.4927\n",
       "Epoch 43/50\n",
-      "270/270 [==============================] - 0s 465us/sample - loss: 4.1861 - mse: 4.1861 - mae: 1.5076 - val_loss: 15.7510 - val_mse: 15.7510 - val_mae: 2.7279\n",
+      "270/270 [==============================] - 0s 630us/sample - loss: 4.7845 - mean_squared_error: 4.7845 - mean_absolute_error: 1.6202 - val_loss: 14.2937 - val_mean_squared_error: 14.2937 - val_mean_absolute_error: 2.4799\n",
       "Epoch 44/50\n",
-      "270/270 [==============================] - 0s 462us/sample - loss: 4.1128 - mse: 4.1128 - mae: 1.4810 - val_loss: 15.4814 - val_mse: 15.4814 - val_mae: 2.6562\n",
+      "270/270 [==============================] - 0s 653us/sample - loss: 4.6612 - mean_squared_error: 4.6612 - mean_absolute_error: 1.5866 - val_loss: 14.2170 - val_mean_squared_error: 14.2170 - val_mean_absolute_error: 2.5172\n",
       "Epoch 45/50\n",
-      "270/270 [==============================] - 0s 441us/sample - loss: 4.2171 - mse: 4.2171 - mae: 1.5205 - val_loss: 16.3839 - val_mse: 16.3839 - val_mae: 2.8194\n",
+      "270/270 [==============================] - 0s 762us/sample - loss: 4.6086 - mean_squared_error: 4.6086 - mean_absolute_error: 1.5453 - val_loss: 14.6632 - val_mean_squared_error: 14.6632 - val_mean_absolute_error: 2.4844\n",
       "Epoch 46/50\n",
-      "270/270 [==============================] - 0s 422us/sample - loss: 4.2609 - mse: 4.2609 - mae: 1.5548 - val_loss: 15.3587 - val_mse: 15.3587 - val_mae: 2.7161\n",
+      "270/270 [==============================] - 0s 524us/sample - loss: 4.8043 - mean_squared_error: 4.8043 - mean_absolute_error: 1.6197 - val_loss: 14.0973 - val_mean_squared_error: 14.0973 - val_mean_absolute_error: 2.4765\n",
       "Epoch 47/50\n",
-      "270/270 [==============================] - 0s 454us/sample - loss: 4.4635 - mse: 4.4635 - mae: 1.5440 - val_loss: 15.7736 - val_mse: 15.7736 - val_mae: 2.7184\n",
+      "270/270 [==============================] - 0s 508us/sample - loss: 4.4674 - mean_squared_error: 4.4674 - mean_absolute_error: 1.5543 - val_loss: 14.0363 - val_mean_squared_error: 14.0363 - val_mean_absolute_error: 2.4702\n",
       "Epoch 48/50\n",
-      "270/270 [==============================] - 0s 426us/sample - loss: 3.7406 - mse: 3.7406 - mae: 1.4147 - val_loss: 15.6718 - val_mse: 15.6718 - val_mae: 2.7468\n",
+      "270/270 [==============================] - 0s 539us/sample - loss: 4.4979 - mean_squared_error: 4.4979 - mean_absolute_error: 1.5952 - val_loss: 14.3432 - val_mean_squared_error: 14.3432 - val_mean_absolute_error: 2.4955\n",
       "Epoch 49/50\n",
-      "270/270 [==============================] - 0s 445us/sample - loss: 3.6173 - mse: 3.6173 - mae: 1.3816 - val_loss: 15.7291 - val_mse: 15.7291 - val_mae: 2.7789\n",
+      "270/270 [==============================] - 0s 627us/sample - loss: 4.4148 - mean_squared_error: 4.4148 - mean_absolute_error: 1.5329 - val_loss: 14.1472 - val_mean_squared_error: 14.1472 - val_mean_absolute_error: 2.5052\n",
       "Epoch 50/50\n",
-      "270/270 [==============================] - 0s 430us/sample - loss: 3.6303 - mse: 3.6303 - mae: 1.4266 - val_loss: 15.4937 - val_mse: 15.4937 - val_mae: 2.7390\n"
+      "270/270 [==============================] - 0s 639us/sample - loss: 4.3466 - mean_squared_error: 4.3466 - mean_absolute_error: 1.4921 - val_loss: 14.3736 - val_mean_squared_error: 14.3736 - val_mean_absolute_error: 2.4799\n"
      ]
     },
     {
      "data": {
       "text/plain": [
-       "<tensorflow.python.keras.callbacks.History at 0x7f315c319be0>"
+       "<tensorflow.python.keras.callbacks.History at 0x22650e6bb70>"
       ]
      },
-     "execution_count": 8,
+     "execution_count": 11,
      "metadata": {},
      "output_type": "execute_result"
     }
    ],
    "source": [
-    "wandb.init(project=\"boston\", entity=\"lambda-ds7\") #Initializes and Experiment\n",
+    "wandb.init(project=\"ds9-boston\", entity=\"ds8\") #Initializes and Experiment\n",
     "\n",
     "# Important Hyperparameters\n",
     "X =  x_train\n",
@@ -1153,9 +1015,9 @@
  ],
  "metadata": {
   "kernelspec": {
-   "display_name": "conda_tensorflow_p36",
+   "display_name": "U4-S2-NNF",
    "language": "python",
-   "name": "conda_tensorflow_p36"
+   "name": "u4-s2-nnf"
   },
   "language_info": {
    "codemirror_mode": {
@@ -1167,7 +1029,7 @@
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
-   "version": "3.6.5"
+   "version": "3.7.0"
   }
  },
  "nbformat": 4,
