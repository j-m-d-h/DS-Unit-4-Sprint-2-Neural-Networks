diff --git a/module1-Intro-to-Neural-Networks/LS_DS_421_Intro_to_NN_Assignment.ipynb b/module1-Intro-to-Neural-Networks/LS_DS_421_Intro_to_NN_Assignment.ipynb
index af0d88b..c4cca8b 100644
--- a/module1-Intro-to-Neural-Networks/LS_DS_421_Intro_to_NN_Assignment.ipynb
+++ b/module1-Intro-to-Neural-Networks/LS_DS_421_Intro_to_NN_Assignment.ipynb
@@ -77,7 +77,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 2,
+   "execution_count": 1,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -343,9 +343,9 @@
    "version": "0.3.2"
   },
   "kernelspec": {
-   "display_name": "Python 3",
+   "display_name": "U4-S2-NNF",
    "language": "python",
-   "name": "python3"
+   "name": "u4-s2-nnf"
   },
   "language_info": {
    "codemirror_mode": {
@@ -357,9 +357,9 @@
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
-   "version": "3.7.3"
+   "version": "3.7.0"
   }
  },
  "nbformat": 4,
- "nbformat_minor": 2
+ "nbformat_minor": 4
 }
diff --git a/module2-backpropagation/LS_DS_422_Backprop_Assignment.ipynb b/module2-backpropagation/LS_DS_422_Backprop_Assignment.ipynb
index 307b203..8d32ee3 100644
--- a/module2-backpropagation/LS_DS_422_Backprop_Assignment.ipynb
+++ b/module2-backpropagation/LS_DS_422_Backprop_Assignment.ipynb
@@ -31,7 +31,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 1,
    "metadata": {
     "colab": {},
     "colab_type": "code",
@@ -39,7 +39,517 @@
    },
    "outputs": [],
    "source": [
-    "##### Your Code Here #####"
+    "import numpy as np\n",
+    "\n",
+    "X = np.array(([0,0,1],\n",
+    "              [0,1,1],\n",
+    "              [1,0,1],\n",
+    "              [0,1,0],\n",
+    "              [1,0,0],\n",
+    "              [1,1,1],\n",
+    "              [0,0,0]), dtype=float)\n",
+    "\n",
+    "y = np.array(([0],\n",
+    "              [1],\n",
+    "              [1],\n",
+    "              [1],\n",
+    "              [1],\n",
+    "              [0],\n",
+    "              [0]), dtype=float)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 19,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "class NeuralNetwork:\n",
+    "    def __init__(self):\n",
+    "\n",
+    "        self.inputs = 3\n",
+    "        self.hiddenNodes = 4\n",
+    "        self.outputNodes = 1\n",
+    "\n",
+    "        self.weights1 = np.random.rand(self.inputs, self.hiddenNodes)\n",
+    "       \n",
+    "        self.weights2 = np.random.rand(self.hiddenNodes, self.outputNodes)\n",
+    "        \n",
+    "    def sigmoid(self, s):\n",
+    "        return 1 / (1+np.exp(-s))\n",
+    "\n",
+    "    def sigmoidPrime(self, s):\n",
+    "        return s * (1 - s)\n",
+    "    \n",
+    "    def feed_forward(self, X):\n",
+    "        \n",
+    "        self.hidden_sum = np.dot(X, self.weights1)\n",
+    "        \n",
+    "        self.activated_hidden = self.sigmoid(self.hidden_sum)\n",
+    "        \n",
+    "        self.output_sum = np.dot(self.activated_hidden, self.weights2)\n",
+    "        \n",
+    "        self.activated_output = self.sigmoid(self.output_sum)\n",
+    "        \n",
+    "        return self.activated_output\n",
+    "    \n",
+    "    def back_prop(self, X, y, o):\n",
+    "\n",
+    "        self.o_error = y - o\n",
+    "        \n",
+    "        self.o_delta = self.o_error * self.sigmoidPrime(o)\n",
+    "        \n",
+    "        self.z2_error = self.o_delta.dot(self.weights2.T)\n",
+    "        \n",
+    "        self.z2_delta = self.z2_error * self.sigmoidPrime(self.activated_hidden)\n",
+    "        \n",
+    "        self.weights1 += X.T.dot(self.z2_delta)\n",
+    "\n",
+    "        self.weights2 += self.activated_hidden.T.dot(self.o_delta)\n",
+    "        \n",
+    "\n",
+    "    def train(self, X, y):\n",
+    "        o = self.feed_forward(X)\n",
+    "        self.back_prop(X,y,o)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 20,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "neural_net = NeuralNetwork()\n",
+    "\n",
+    "neural_net.train(X, y)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 24,
+   "metadata": {},
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "+---------EPOCH 1---------+\n",
+      "Input: \n",
+      " [[0. 0. 1.]\n",
+      " [0. 1. 1.]\n",
+      " [1. 0. 1.]\n",
+      " [0. 1. 0.]\n",
+      " [1. 0. 0.]\n",
+      " [1. 1. 1.]\n",
+      " [0. 0. 0.]]\n",
+      "Predicted Output: \n",
+      " [[0.00228424]\n",
+      " [0.98792048]\n",
+      " [0.98807781]\n",
+      " [0.9891835 ]\n",
+      " [0.98900968]\n",
+      " [0.00597504]\n",
+      " [0.02792256]]\n",
+      "Actual Output: \n",
+      " [[0.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [0.]\n",
+      " [0.]]\n",
+      "Loss: \n",
+      " 0.00019234654682418495\n",
+      "+---------EPOCH 2---------+\n",
+      "Input: \n",
+      " [[0. 0. 1.]\n",
+      " [0. 1. 1.]\n",
+      " [1. 0. 1.]\n",
+      " [0. 1. 0.]\n",
+      " [1. 0. 0.]\n",
+      " [1. 1. 1.]\n",
+      " [0. 0. 0.]]\n",
+      "Predicted Output: \n",
+      " [[0.0022841 ]\n",
+      " [0.98792111]\n",
+      " [0.98807843]\n",
+      " [0.98918404]\n",
+      " [0.98901023]\n",
+      " [0.00597462]\n",
+      " [0.02792116]]\n",
+      "Actual Output: \n",
+      " [[0.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [0.]\n",
+      " [0.]]\n",
+      "Loss: \n",
+      " 0.00019232686507185244\n",
+      "+---------EPOCH 3---------+\n",
+      "Input: \n",
+      " [[0. 0. 1.]\n",
+      " [0. 1. 1.]\n",
+      " [1. 0. 1.]\n",
+      " [0. 1. 0.]\n",
+      " [1. 0. 0.]\n",
+      " [1. 1. 1.]\n",
+      " [0. 0. 0.]]\n",
+      "Predicted Output: \n",
+      " [[0.00228395]\n",
+      " [0.98792175]\n",
+      " [0.98807905]\n",
+      " [0.98918457]\n",
+      " [0.98901078]\n",
+      " [0.00597421]\n",
+      " [0.02791977]]\n",
+      "Actual Output: \n",
+      " [[0.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [0.]\n",
+      " [0.]]\n",
+      "Loss: \n",
+      " 0.00019230718733502565\n",
+      "+---------EPOCH 4---------+\n",
+      "Input: \n",
+      " [[0. 0. 1.]\n",
+      " [0. 1. 1.]\n",
+      " [1. 0. 1.]\n",
+      " [0. 1. 0.]\n",
+      " [1. 0. 0.]\n",
+      " [1. 1. 1.]\n",
+      " [0. 0. 0.]]\n",
+      "Predicted Output: \n",
+      " [[0.0022838 ]\n",
+      " [0.98792238]\n",
+      " [0.98807968]\n",
+      " [0.98918511]\n",
+      " [0.98901134]\n",
+      " [0.00597379]\n",
+      " [0.02791837]]\n",
+      "Actual Output: \n",
+      " [[0.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [0.]\n",
+      " [0.]]\n",
+      "Loss: \n",
+      " 0.00019228751361247666\n",
+      "+---------EPOCH 5---------+\n",
+      "Input: \n",
+      " [[0. 0. 1.]\n",
+      " [0. 1. 1.]\n",
+      " [1. 0. 1.]\n",
+      " [0. 1. 0.]\n",
+      " [1. 0. 0.]\n",
+      " [1. 1. 1.]\n",
+      " [0. 0. 0.]]\n",
+      "Predicted Output: \n",
+      " [[0.00228365]\n",
+      " [0.98792302]\n",
+      " [0.9880803 ]\n",
+      " [0.98918565]\n",
+      " [0.98901189]\n",
+      " [0.00597338]\n",
+      " [0.02791697]]\n",
+      "Actual Output: \n",
+      " [[0.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [0.]\n",
+      " [0.]]\n",
+      "Loss: \n",
+      " 0.00019226784390298147\n",
+      "+---------EPOCH 6---------+\n",
+      "Input: \n",
+      " [[0. 0. 1.]\n",
+      " [0. 1. 1.]\n",
+      " [1. 0. 1.]\n",
+      " [0. 1. 0.]\n",
+      " [1. 0. 0.]\n",
+      " [1. 1. 1.]\n",
+      " [0. 0. 0.]]\n",
+      "Predicted Output: \n",
+      " [[0.00228351]\n",
+      " [0.98792366]\n",
+      " [0.98808092]\n",
+      " [0.98918619]\n",
+      " [0.98901244]\n",
+      " [0.00597297]\n",
+      " [0.02791557]]\n",
+      "Actual Output: \n",
+      " [[0.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [0.]\n",
+      " [0.]]\n",
+      "Loss: \n",
+      " 0.0001922481782053117\n",
+      "+---------EPOCH 7---------+\n",
+      "Input: \n",
+      " [[0. 0. 1.]\n",
+      " [0. 1. 1.]\n",
+      " [1. 0. 1.]\n",
+      " [0. 1. 0.]\n",
+      " [1. 0. 0.]\n",
+      " [1. 1. 1.]\n",
+      " [0. 0. 0.]]\n",
+      "Predicted Output: \n",
+      " [[0.00228336]\n",
+      " [0.98792429]\n",
+      " [0.98808154]\n",
+      " [0.98918673]\n",
+      " [0.989013  ]\n",
+      " [0.00597255]\n",
+      " [0.02791417]]\n",
+      "Actual Output: \n",
+      " [[0.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [0.]\n",
+      " [0.]]\n",
+      "Loss: \n",
+      " 0.00019222851651824196\n",
+      "+---------EPOCH 8---------+\n",
+      "Input: \n",
+      " [[0. 0. 1.]\n",
+      " [0. 1. 1.]\n",
+      " [1. 0. 1.]\n",
+      " [0. 1. 0.]\n",
+      " [1. 0. 0.]\n",
+      " [1. 1. 1.]\n",
+      " [0. 0. 0.]]\n",
+      "Predicted Output: \n",
+      " [[0.00228321]\n",
+      " [0.98792493]\n",
+      " [0.98808217]\n",
+      " [0.98918727]\n",
+      " [0.98901355]\n",
+      " [0.00597214]\n",
+      " [0.02791278]]\n",
+      "Actual Output: \n",
+      " [[0.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [0.]\n",
+      " [0.]]\n",
+      "Loss: \n",
+      " 0.00019220885884054675\n",
+      "+---------EPOCH 9---------+\n",
+      "Input: \n",
+      " [[0. 0. 1.]\n",
+      " [0. 1. 1.]\n",
+      " [1. 0. 1.]\n",
+      " [0. 1. 0.]\n",
+      " [1. 0. 0.]\n",
+      " [1. 1. 1.]\n",
+      " [0. 0. 0.]]\n",
+      "Predicted Output: \n",
+      " [[0.00228307]\n",
+      " [0.98792556]\n",
+      " [0.98808279]\n",
+      " [0.98918781]\n",
+      " [0.9890141 ]\n",
+      " [0.00597172]\n",
+      " [0.02791138]]\n",
+      "Actual Output: \n",
+      " [[0.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [0.]\n",
+      " [0.]]\n",
+      "Loss: \n",
+      " 0.00019218920517100014\n",
+      "+---------EPOCH 10---------+\n",
+      "Input: \n",
+      " [[0. 0. 1.]\n",
+      " [0. 1. 1.]\n",
+      " [1. 0. 1.]\n",
+      " [0. 1. 0.]\n",
+      " [1. 0. 0.]\n",
+      " [1. 1. 1.]\n",
+      " [0. 0. 0.]]\n",
+      "Predicted Output: \n",
+      " [[0.00228292]\n",
+      " [0.9879262 ]\n",
+      " [0.98808341]\n",
+      " [0.98918834]\n",
+      " [0.98901465]\n",
+      " [0.00597131]\n",
+      " [0.02790998]]\n",
+      "Actual Output: \n",
+      " [[0.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [0.]\n",
+      " [0.]]\n",
+      "Loss: \n",
+      " 0.00019216955550838005\n",
+      "+---------EPOCH 1000---------+\n",
+      "Input: \n",
+      " [[0. 0. 1.]\n",
+      " [0. 1. 1.]\n",
+      " [1. 0. 1.]\n",
+      " [0. 1. 0.]\n",
+      " [1. 0. 0.]\n",
+      " [1. 1. 1.]\n",
+      " [0. 0. 0.]]\n",
+      "Predicted Output: \n",
+      " [[0.00214827]\n",
+      " [0.9885101 ]\n",
+      " [0.98865575]\n",
+      " [0.98968452]\n",
+      " [0.98952374]\n",
+      " [0.00559406]\n",
+      " [0.02662201]]\n",
+      "Actual Output: \n",
+      " [[0.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [0.]\n",
+      " [0.]]\n",
+      "Loss: \n",
+      " 0.0001745015945010655\n",
+      "+---------EPOCH 2000---------+\n",
+      "Input: \n",
+      " [[0. 0. 1.]\n",
+      " [0. 1. 1.]\n",
+      " [1. 0. 1.]\n",
+      " [0. 1. 0.]\n",
+      " [1. 0. 0.]\n",
+      " [1. 1. 1.]\n",
+      " [0. 0. 0.]]\n",
+      "Predicted Output: \n",
+      " [[0.00203154]\n",
+      " [0.98902255]\n",
+      " [0.98915837]\n",
+      " [0.99012182]\n",
+      " [0.98997202]\n",
+      " [0.00526887]\n",
+      " [0.02548701]]\n",
+      "Actual Output: \n",
+      " [[0.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [0.]\n",
+      " [0.]]\n",
+      "Loss: \n",
+      " 0.00015966570704700352\n",
+      "+---------EPOCH 3000---------+\n",
+      "Input: \n",
+      " [[0. 0. 1.]\n",
+      " [0. 1. 1.]\n",
+      " [1. 0. 1.]\n",
+      " [0. 1. 0.]\n",
+      " [1. 0. 0.]\n",
+      " [1. 1. 1.]\n",
+      " [0. 0. 0.]]\n",
+      "Predicted Output: \n",
+      " [[0.00193011]\n",
+      " [0.98947286]\n",
+      " [0.98960027]\n",
+      " [0.99050752]\n",
+      " [0.99036711]\n",
+      " [0.00498775]\n",
+      " [0.02448604]]\n",
+      "Actual Output: \n",
+      " [[0.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [0.]\n",
+      " [0.]]\n",
+      "Loss: \n",
+      " 0.00014714913902624747\n",
+      "+---------EPOCH 4000---------+\n",
+      "Input: \n",
+      " [[0. 0. 1.]\n",
+      " [0. 1. 1.]\n",
+      " [1. 0. 1.]\n",
+      " [0. 1. 0.]\n",
+      " [1. 0. 0.]\n",
+      " [1. 1. 1.]\n",
+      " [0. 0. 0.]]\n",
+      "Predicted Output: \n",
+      " [[0.00184099]\n",
+      " [0.98987261]\n",
+      " [0.98999274]\n",
+      " [0.99085106]\n",
+      " [0.99071876]\n",
+      " [0.00474187]\n",
+      " [0.02359464]]\n",
+      "Actual Output: \n",
+      " [[0.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [0.]\n",
+      " [0.]]\n",
+      "Loss: \n",
+      " 0.00013644789681822435\n",
+      "+---------EPOCH 5000---------+\n",
+      "Input: \n",
+      " [[0. 0. 1.]\n",
+      " [0. 1. 1.]\n",
+      " [1. 0. 1.]\n",
+      " [0. 1. 0.]\n",
+      " [1. 0. 0.]\n",
+      " [1. 1. 1.]\n",
+      " [0. 0. 0.]]\n",
+      "Predicted Output: \n",
+      " [[0.00176194]\n",
+      " [0.99023057]\n",
+      " [0.99034434]\n",
+      " [0.9911596 ]\n",
+      " [0.9910344 ]\n",
+      " [0.00452469]\n",
+      " [0.02279415]]\n",
+      "Actual Output: \n",
+      " [[0.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [1.]\n",
+      " [0.]\n",
+      " [0.]]\n",
+      "Loss: \n",
+      " 0.0001271940938834837\n"
+     ]
+    }
+   ],
+   "source": [
+    "for i in range(5000):\n",
+    "    if (i+1 in range(1, 11)) or ((i+1) % 1000 ==0):\n",
+    "        print('+' + '---' * 3 + f'EPOCH {i+1}' + '---'*3 + '+')\n",
+    "        print('Input: \\n', X)\n",
+    "        print('Predicted Output: \\n', str(neural_net.feed_forward(X)))\n",
+    "        print('Actual Output: \\n', y)\n",
+    "        print(\"Loss: \\n\", str(np.mean(np.square(y - neural_net.feed_forward(X)))))\n",
+    "    neural_net.train(X,y)"
    ]
   },
   {
@@ -242,9 +752,9 @@
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
-   "version": "3.7.3"
+   "version": "3.7.4"
   }
  },
  "nbformat": 4,
- "nbformat_minor": 2
+ "nbformat_minor": 4
 }
diff --git a/module2-backpropagation/LS_DS_422_Gradient_Descent_Backprop_Lecture.ipynb b/module2-backpropagation/LS_DS_422_Gradient_Descent_Backprop_Lecture.ipynb
index 8e64e1c..ac9372d 100644
--- a/module2-backpropagation/LS_DS_422_Gradient_Descent_Backprop_Lecture.ipynb
+++ b/module2-backpropagation/LS_DS_422_Gradient_Descent_Backprop_Lecture.ipynb
@@ -1486,7 +1486,7 @@
  ],
  "metadata": {
   "kernelspec": {
-   "display_name": "U4-S2-NNF (Python 3.7)",
+   "display_name": "U4-S2-NNF",
    "language": "python",
    "name": "u4-s2-nnf"
   },
@@ -1500,7 +1500,7 @@
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
-   "version": "3.7.3"
+   "version": "3.7.0"
   }
  },
  "nbformat": 4,
diff --git a/module3-Intro-to-Keras/LS_DS_423_Keras_Assignment.ipynb b/module3-Intro-to-Keras/LS_DS_423_Keras_Assignment.ipynb
index 2457723..c2606b3 100644
--- a/module3-Intro-to-Keras/LS_DS_423_Keras_Assignment.ipynb
+++ b/module3-Intro-to-Keras/LS_DS_423_Keras_Assignment.ipynb
@@ -32,7 +32,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 10,
    "metadata": {
     "colab": {},
     "colab_type": "code",
@@ -40,7 +40,395 @@
    },
    "outputs": [],
    "source": [
-    "##### Your Code Here #####"
+    "from tensorflow.keras.datasets import boston_housing\n",
+    "from tensorflow.keras.utils import to_categorical\n",
+    "from tensorflow.keras.models import Sequential\n",
+    "from tensorflow.keras.layers import Dense"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 15,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 30,
+   "metadata": {},
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "[[1.38516817e-02 0.00000000e+00 2.93439077e-01 ... 9.54545455e-01\n",
+      "  1.00000000e+00 4.93020806e-01]\n",
+      " [2.44672171e-04 8.25000000e-01 7.31795242e-02 ... 6.68181818e-01\n",
+      "  9.96170320e-01 8.19067685e-02]\n",
+      " [5.50509013e-02 0.00000000e+00 6.52487383e-01 ... 9.18181818e-01\n",
+      "  9.46132527e-01 8.58572557e-02]\n",
+      " ...\n",
+      " [3.89542372e-04 3.50000000e-01 2.18457102e-01 ... 7.68181818e-01\n",
+      "  9.12698413e-01 2.06215433e-01]\n",
+      " [2.41545492e-02 0.00000000e+00 7.05839942e-01 ... 6.68181818e-01\n",
+      "  6.59989922e-01 4.15854622e-01]\n",
+      " [1.61728642e-04 6.00000000e-01 1.05623648e-01 ... 7.09090909e-01\n",
+      "  9.49105568e-01 1.15354227e-01]]\n"
+     ]
+    }
+   ],
+   "source": [
+    "X_train = X_train / np.amax(X_train, axis=0)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 31,
+   "metadata": {},
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "1.0"
+      ]
+     },
+     "execution_count": 31,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": []
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 32,
+   "metadata": {},
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Epoch 1/150\n",
+      "404/404 [==============================] - 0s 320us/sample - loss: 311.2546 - acc: 0.0000e+00\n",
+      "Epoch 2/150\n",
+      "404/404 [==============================] - 0s 62us/sample - loss: 307.6520 - acc: 0.0000e+00\n",
+      "Epoch 3/150\n",
+      "404/404 [==============================] - 0s 72us/sample - loss: 299.9498 - acc: 0.0000e+00\n",
+      "Epoch 4/150\n",
+      "404/404 [==============================] - 0s 73us/sample - loss: 286.7898 - acc: 0.0000e+00\n",
+      "Epoch 5/150\n",
+      "404/404 [==============================] - 0s 82us/sample - loss: 280.6785 - acc: 0.0000e+00\n",
+      "Epoch 6/150\n",
+      "404/404 [==============================] - 0s 74us/sample - loss: 274.9955 - acc: 0.0000e+00\n",
+      "Epoch 7/150\n",
+      "404/404 [==============================] - 0s 78us/sample - loss: 269.4262 - acc: 0.0000e+00\n",
+      "Epoch 8/150\n",
+      "404/404 [==============================] - 0s 77us/sample - loss: 267.5206 - acc: 0.0000e+00\n",
+      "Epoch 9/150\n",
+      "404/404 [==============================] - 0s 79us/sample - loss: 264.9829 - acc: 0.0000e+00\n",
+      "Epoch 10/150\n",
+      "404/404 [==============================] - 0s 81us/sample - loss: 261.0259 - acc: 0.0000e+00\n",
+      "Epoch 11/150\n",
+      "404/404 [==============================] - 0s 89us/sample - loss: 256.7242 - acc: 0.0000e+00\n",
+      "Epoch 12/150\n",
+      "404/404 [==============================] - 0s 89us/sample - loss: 252.4377 - acc: 0.0000e+00\n",
+      "Epoch 13/150\n",
+      "404/404 [==============================] - 0s 84us/sample - loss: 239.5965 - acc: 0.0000e+00\n",
+      "Epoch 14/150\n",
+      "404/404 [==============================] - 0s 89us/sample - loss: 225.5494 - acc: 0.0000e+00\n",
+      "Epoch 15/150\n",
+      "404/404 [==============================] - 0s 97us/sample - loss: 213.4369 - acc: 0.0000e+00\n",
+      "Epoch 16/150\n",
+      "404/404 [==============================] - 0s 94us/sample - loss: 194.7965 - acc: 0.0000e+00\n",
+      "Epoch 17/150\n",
+      "404/404 [==============================] - 0s 101us/sample - loss: 175.8713 - acc: 0.0000e+00\n",
+      "Epoch 18/150\n",
+      "404/404 [==============================] - 0s 94us/sample - loss: 162.1834 - acc: 0.0000e+00\n",
+      "Epoch 19/150\n",
+      "404/404 [==============================] - 0s 109us/sample - loss: 138.6354 - acc: 0.0000e+00\n",
+      "Epoch 20/150\n",
+      "404/404 [==============================] - 0s 81us/sample - loss: 110.9728 - acc: 0.0000e+00\n",
+      "Epoch 21/150\n",
+      "404/404 [==============================] - 0s 75us/sample - loss: 91.4688 - acc: 0.0000e+00\n",
+      "Epoch 22/150\n",
+      "404/404 [==============================] - 0s 77us/sample - loss: 74.5290 - acc: 0.0000e+00\n",
+      "Epoch 23/150\n",
+      "404/404 [==============================] - 0s 79us/sample - loss: 58.4907 - acc: 0.0000e+00\n",
+      "Epoch 24/150\n",
+      "404/404 [==============================] - 0s 79us/sample - loss: 38.2235 - acc: 0.0000e+00\n",
+      "Epoch 25/150\n",
+      "404/404 [==============================] - 0s 71us/sample - loss: 7.9538 - acc: 0.0000e+00\n",
+      "Epoch 26/150\n",
+      "404/404 [==============================] - 0s 74us/sample - loss: -9.6161 - acc: 0.0000e+00\n",
+      "Epoch 27/150\n",
+      "404/404 [==============================] - 0s 75us/sample - loss: -22.1051 - acc: 0.0000e+00\n",
+      "Epoch 28/150\n",
+      "404/404 [==============================] - 0s 80us/sample - loss: -36.5693 - acc: 0.0000e+00\n",
+      "Epoch 29/150\n",
+      "404/404 [==============================] - 0s 75us/sample - loss: -51.2666 - acc: 0.0000e+00\n",
+      "Epoch 30/150\n",
+      "404/404 [==============================] - 0s 95us/sample - loss: -63.1772 - acc: 0.0000e+00\n",
+      "Epoch 31/150\n",
+      "404/404 [==============================] - 0s 79us/sample - loss: -79.9133 - acc: 0.0000e+00\n",
+      "Epoch 32/150\n",
+      "404/404 [==============================] - 0s 91us/sample - loss: -97.0848 - acc: 0.0000e+00\n",
+      "Epoch 33/150\n",
+      "404/404 [==============================] - 0s 81us/sample - loss: -114.9622 - acc: 0.0000e+00\n",
+      "Epoch 34/150\n",
+      "404/404 [==============================] - 0s 91us/sample - loss: -129.6976 - acc: 0.0000e+00\n",
+      "Epoch 35/150\n",
+      "404/404 [==============================] - 0s 96us/sample - loss: -145.4799 - acc: 0.0000e+00\n",
+      "Epoch 36/150\n",
+      "404/404 [==============================] - 0s 91us/sample - loss: -169.0932 - acc: 0.0000e+00\n",
+      "Epoch 37/150\n",
+      "404/404 [==============================] - 0s 82us/sample - loss: -189.5318 - acc: 0.0000e+00\n",
+      "Epoch 38/150\n",
+      "404/404 [==============================] - 0s 81us/sample - loss: -211.3477 - acc: 0.0000e+00\n",
+      "Epoch 39/150\n",
+      "404/404 [==============================] - 0s 80us/sample - loss: -248.3458 - acc: 0.0000e+00\n",
+      "Epoch 40/150\n",
+      "404/404 [==============================] - 0s 78us/sample - loss: -270.6149 - acc: 0.0000e+00\n",
+      "Epoch 41/150\n",
+      "404/404 [==============================] - 0s 88us/sample - loss: -278.9053 - acc: 0.0000e+00\n",
+      "Epoch 42/150\n",
+      "404/404 [==============================] - 0s 88us/sample - loss: -286.9201 - acc: 0.0000e+00\n",
+      "Epoch 43/150\n",
+      "404/404 [==============================] - 0s 92us/sample - loss: -292.4355 - acc: 0.0000e+00\n",
+      "Epoch 44/150\n",
+      "404/404 [==============================] - 0s 84us/sample - loss: -298.1876 - acc: 0.0000e+00\n",
+      "Epoch 45/150\n",
+      "404/404 [==============================] - 0s 83us/sample - loss: -302.8983 - acc: 0.0000e+00\n",
+      "Epoch 46/150\n",
+      "404/404 [==============================] - 0s 84us/sample - loss: -309.3471 - acc: 0.0000e+00\n",
+      "Epoch 47/150\n",
+      "404/404 [==============================] - 0s 80us/sample - loss: -314.4464 - acc: 0.0000e+00\n",
+      "Epoch 48/150\n",
+      "404/404 [==============================] - 0s 84us/sample - loss: -315.5622 - acc: 0.0000e+00\n",
+      "Epoch 49/150\n",
+      "404/404 [==============================] - 0s 83us/sample - loss: -315.6718 - acc: 0.0000e+00\n",
+      "Epoch 50/150\n",
+      "404/404 [==============================] - 0s 88us/sample - loss: -316.4920 - acc: 0.0000e+00\n",
+      "Epoch 51/150\n",
+      "404/404 [==============================] - 0s 79us/sample - loss: -317.4937 - acc: 0.0000e+00\n",
+      "Epoch 52/150\n",
+      "404/404 [==============================] - 0s 84us/sample - loss: -318.0948 - acc: 0.0000e+00\n",
+      "Epoch 53/150\n",
+      "404/404 [==============================] - 0s 82us/sample - loss: -318.1733 - acc: 0.0000e+00\n",
+      "Epoch 54/150\n",
+      "404/404 [==============================] - 0s 86us/sample - loss: -318.2442 - acc: 0.0000e+00\n",
+      "Epoch 55/150\n",
+      "404/404 [==============================] - 0s 84us/sample - loss: -318.3199 - acc: 0.0000e+00\n",
+      "Epoch 56/150\n",
+      "404/404 [==============================] - 0s 91us/sample - loss: -318.5288 - acc: 0.0000e+00\n",
+      "Epoch 57/150\n",
+      "404/404 [==============================] - 0s 87us/sample - loss: -319.2313 - acc: 0.0000e+00\n",
+      "Epoch 58/150\n",
+      "404/404 [==============================] - 0s 81us/sample - loss: -319.6626 - acc: 0.0000e+00\n",
+      "Epoch 59/150\n",
+      "404/404 [==============================] - 0s 68us/sample - loss: -323.3065 - acc: 0.0000e+00\n",
+      "Epoch 60/150\n",
+      "404/404 [==============================] - ETA: 0s - loss: -363.1582 - acc: 0.0000e+ - 0s 62us/sample - loss: -326.7470 - acc: 0.0000e+00\n",
+      "Epoch 61/150\n",
+      "404/404 [==============================] - 0s 70us/sample - loss: -327.3436 - acc: 0.0000e+00\n",
+      "Epoch 62/150\n",
+      "404/404 [==============================] - 0s 72us/sample - loss: -327.3993 - acc: 0.0000e+00\n",
+      "Epoch 63/150\n",
+      "404/404 [==============================] - 0s 78us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 64/150\n",
+      "404/404 [==============================] - 0s 79us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 65/150\n",
+      "404/404 [==============================] - 0s 89us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 66/150\n",
+      "404/404 [==============================] - 0s 79us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 67/150\n",
+      "404/404 [==============================] - 0s 79us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 68/150\n",
+      "404/404 [==============================] - 0s 87us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 69/150\n",
+      "404/404 [==============================] - 0s 82us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 70/150\n",
+      "404/404 [==============================] - 0s 90us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 71/150\n",
+      "404/404 [==============================] - 0s 81us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 72/150\n",
+      "404/404 [==============================] - 0s 87us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 73/150\n",
+      "404/404 [==============================] - 0s 82us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 74/150\n",
+      "404/404 [==============================] - 0s 76us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 75/150\n",
+      "404/404 [==============================] - 0s 81us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 76/150\n",
+      "404/404 [==============================] - 0s 77us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 77/150\n",
+      "404/404 [==============================] - 0s 84us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 78/150\n",
+      "404/404 [==============================] - 0s 82us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 79/150\n",
+      "404/404 [==============================] - 0s 95us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 80/150\n",
+      "404/404 [==============================] - 0s 93us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 81/150\n",
+      "404/404 [==============================] - 0s 84us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 82/150\n",
+      "404/404 [==============================] - 0s 79us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 83/150\n",
+      "404/404 [==============================] - 0s 82us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 84/150\n",
+      "404/404 [==============================] - 0s 85us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 85/150\n",
+      "404/404 [==============================] - 0s 83us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 86/150\n",
+      "404/404 [==============================] - 0s 87us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 87/150\n",
+      "404/404 [==============================] - 0s 87us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 88/150\n",
+      "404/404 [==============================] - 0s 99us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 89/150\n",
+      "404/404 [==============================] - 0s 93us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 90/150\n",
+      "404/404 [==============================] - 0s 96us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 91/150\n",
+      "404/404 [==============================] - 0s 109us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 92/150\n",
+      "404/404 [==============================] - 0s 90us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 93/150\n",
+      "404/404 [==============================] - 0s 115us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 94/150\n",
+      "404/404 [==============================] - 0s 94us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 95/150\n",
+      "404/404 [==============================] - 0s 108us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 96/150\n",
+      "404/404 [==============================] - 0s 101us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 97/150\n",
+      "404/404 [==============================] - 0s 98us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 98/150\n",
+      "404/404 [==============================] - 0s 94us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 99/150\n",
+      "404/404 [==============================] - 0s 98us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 100/150\n",
+      "404/404 [==============================] - 0s 98us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 101/150\n",
+      "404/404 [==============================] - 0s 96us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 102/150\n",
+      "404/404 [==============================] - 0s 117us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 103/150\n",
+      "404/404 [==============================] - 0s 81us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 104/150\n",
+      "404/404 [==============================] - 0s 74us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 105/150\n",
+      "404/404 [==============================] - 0s 78us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 106/150\n",
+      "404/404 [==============================] - 0s 79us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 107/150\n",
+      "404/404 [==============================] - 0s 77us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 108/150\n",
+      "404/404 [==============================] - 0s 81us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 109/150\n",
+      "404/404 [==============================] - 0s 84us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 110/150\n",
+      "404/404 [==============================] - 0s 82us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 111/150\n",
+      "404/404 [==============================] - 0s 97us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 112/150\n",
+      "404/404 [==============================] - 0s 91us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 113/150\n",
+      "404/404 [==============================] - 0s 96us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 114/150\n",
+      "404/404 [==============================] - 0s 97us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 115/150\n",
+      "404/404 [==============================] - 0s 89us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 116/150\n",
+      "404/404 [==============================] - 0s 94us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 117/150\n",
+      "404/404 [==============================] - 0s 101us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 118/150\n",
+      "404/404 [==============================] - 0s 79us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 119/150\n",
+      "404/404 [==============================] - 0s 79us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 120/150\n",
+      "404/404 [==============================] - 0s 142us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 121/150\n",
+      "404/404 [==============================] - 0s 109us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 122/150\n",
+      "404/404 [==============================] - 0s 83us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 123/150\n",
+      "404/404 [==============================] - 0s 78us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 124/150\n",
+      "404/404 [==============================] - 0s 73us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 125/150\n",
+      "404/404 [==============================] - 0s 79us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 126/150\n",
+      "404/404 [==============================] - 0s 73us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 127/150\n",
+      "404/404 [==============================] - 0s 73us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 128/150\n",
+      "404/404 [==============================] - 0s 81us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 129/150\n",
+      "404/404 [==============================] - 0s 86us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 130/150\n",
+      "404/404 [==============================] - 0s 82us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 131/150\n",
+      "404/404 [==============================] - 0s 81us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 132/150\n",
+      "404/404 [==============================] - 0s 76us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 133/150\n",
+      "404/404 [==============================] - 0s 81us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 134/150\n",
+      "404/404 [==============================] - 0s 78us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 135/150\n",
+      "404/404 [==============================] - ETA: 0s - loss: -322.7646 - acc: 0.0000e+ - 0s 88us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 136/150\n",
+      "404/404 [==============================] - 0s 101us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 137/150\n",
+      "404/404 [==============================] - 0s 86us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 138/150\n",
+      "404/404 [==============================] - 0s 91us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 139/150\n",
+      "404/404 [==============================] - 0s 99us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 140/150\n",
+      "404/404 [==============================] - 0s 100us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 141/150\n",
+      "404/404 [==============================] - 0s 83us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 142/150\n",
+      "404/404 [==============================] - 0s 82us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 143/150\n",
+      "404/404 [==============================] - 0s 81us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 144/150\n",
+      "404/404 [==============================] - 0s 68us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 145/150\n",
+      "404/404 [==============================] - 0s 77us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 146/150\n",
+      "404/404 [==============================] - 0s 79us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 147/150\n",
+      "404/404 [==============================] - 0s 82us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 148/150\n",
+      "404/404 [==============================] - 0s 85us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 149/150\n",
+      "404/404 [==============================] - 0s 104us/sample - loss: -328.0554 - acc: 0.0000e+00\n",
+      "Epoch 150/150\n",
+      "404/404 [==============================] - 0s 76us/sample - loss: -328.0554 - acc: 0.0000e+00\n"
+     ]
+    },
+    {
+     "data": {
+      "text/plain": [
+       "<tensorflow.python.keras.callbacks.History at 0x26b0ca1c5f8>"
+      ]
+     },
+     "execution_count": 32,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": [
+    "model = Sequential()\n",
+    "model.add(Dense(1, input_dim=13, activation=\"relu\"))\n",
+    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
+    "model.fit(X_train, y_train, epochs=150)"
    ]
   },
   {
@@ -96,9 +484,9 @@
    "version": "0.3.2"
   },
   "kernelspec": {
-   "display_name": "Python 3",
+   "display_name": "U4-S2-NNF",
    "language": "python",
-   "name": "python3"
+   "name": "u4-s2-nnf"
   },
   "language_info": {
    "codemirror_mode": {
@@ -110,9 +498,9 @@
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
-   "version": "3.7.3"
+   "version": "3.7.0"
   }
  },
  "nbformat": 4,
- "nbformat_minor": 2
+ "nbformat_minor": 4
 }
diff --git a/module3-Intro-to-Keras/LS_DS_423_Keras_Lecture.ipynb b/module3-Intro-to-Keras/LS_DS_423_Keras_Lecture.ipynb
index abc92b5..c7e6d4d 100644
--- a/module3-Intro-to-Keras/LS_DS_423_Keras_Lecture.ipynb
+++ b/module3-Intro-to-Keras/LS_DS_423_Keras_Lecture.ipynb
@@ -104,27 +104,39 @@
     "outputId": "12966e66-2297-4f82-85b3-c275a9c38563"
    },
    "outputs": [
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "WARNING: Logging before flag parsing goes to stderr.\n",
+      "W0122 16:35:22.440964 22032 deprecation.py:506] From C:\\ProgramData\\Anaconda3\\envs\\U4-S2-NNF\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
+      "Instructions for updating:\n",
+      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
+      "W0122 16:35:22.472933 22032 deprecation.py:323] From C:\\ProgramData\\Anaconda3\\envs\\U4-S2-NNF\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
+      "Instructions for updating:\n",
+      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
+     ]
+    },
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Train on 4 samples\n",
       "Epoch 1/5\n",
-      "4/4 [==============================] - 1s 184ms/sample - loss: 0.7531 - accuracy: 0.2500\n",
+      "4/4 [==============================] - 0s 15ms/sample - loss: 0.7489 - acc: 0.5000\n",
       "Epoch 2/5\n",
-      "4/4 [==============================] - 0s 1ms/sample - loss: 0.7527 - accuracy: 0.5000\n",
+      "4/4 [==============================] - 0s 244us/sample - loss: 0.7486 - acc: 0.7500\n",
       "Epoch 3/5\n",
-      "4/4 [==============================] - 0s 833us/sample - loss: 0.7524 - accuracy: 0.5000\n",
+      "4/4 [==============================] - 0s 241us/sample - loss: 0.7482 - acc: 0.7500\n",
       "Epoch 4/5\n",
-      "4/4 [==============================] - 0s 760us/sample - loss: 0.7520 - accuracy: 0.5000\n",
+      "4/4 [==============================] - 0s 241us/sample - loss: 0.7479 - acc: 0.7500\n",
       "Epoch 5/5\n",
-      "4/4 [==============================] - 0s 805us/sample - loss: 0.7517 - accuracy: 0.5000\n"
+      "4/4 [==============================] - 0s 243us/sample - loss: 0.7476 - acc: 0.7500\n"
      ]
     },
     {
      "data": {
       "text/plain": [
-       "<tensorflow.python.keras.callbacks.History at 0x7fb4cc4cdeb8>"
+       "<tensorflow.python.keras.callbacks.History at 0x1dc4604a128>"
       ]
      },
      "execution_count": 2,
@@ -160,8 +172,8 @@
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "4/1 [========================================================================================================================] - 0s 21ms/sample - loss: 0.7514 - accuracy: 0.5000\n",
-      "accuracy: 50.0\n"
+      "4/4 [==============================] - 0s 3ms/sample - loss: 0.7473 - acc: 0.7500\n",
+      "acc: 75.0\n"
      ]
     }
    ],
@@ -455,7 +467,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 8,
+   "execution_count": 4,
    "metadata": {
     "colab": {},
     "colab_type": "code",
@@ -483,7 +495,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 9,
+   "execution_count": 5,
    "metadata": {
     "colab": {},
     "colab_type": "code",
@@ -511,7 +523,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 17,
+   "execution_count": 6,
    "metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
@@ -2376,9 +2388,9 @@
    "version": "0.3.2"
   },
   "kernelspec": {
-   "display_name": "Python 3",
+   "display_name": "U4-S2-NNF",
    "language": "python",
-   "name": "python3"
+   "name": "u4-s2-nnf"
   },
   "language_info": {
    "codemirror_mode": {
@@ -2390,7 +2402,7 @@
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
-   "version": "3.6.8"
+   "version": "3.7.0"
   },
   "toc-autonumbering": false,
   "toc-showmarkdowntxt": false
diff --git a/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Assignment.ipynb b/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Assignment.ipynb
index ca65dc6..cf51878 100644
--- a/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Assignment.ipynb
+++ b/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Assignment.ipynb
@@ -91,9 +91,9 @@
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
-   "version": "3.7.3"
+   "version": "3.7.4"
   }
  },
  "nbformat": 4,
- "nbformat_minor": 2
+ "nbformat_minor": 4
 }
diff --git a/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Lecture.ipynb b/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Lecture.ipynb
index 4bb18e9..9421ebb 100644
--- a/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Lecture.ipynb
+++ b/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Lecture.ipynb
@@ -42,7 +42,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 1,
+   "execution_count": 3,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -81,7 +81,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 1,
+   "execution_count": 4,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -106,7 +106,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 2,
+   "execution_count": 5,
    "metadata": {},
    "outputs": [
     {
@@ -170,7 +170,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 3,
+   "execution_count": 6,
    "metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
@@ -182,171 +182,27 @@
    },
    "outputs": [
     {
-     "name": "stdout",
+     "name": "stderr",
      "output_type": "stream",
      "text": [
-      "Train on 404 samples, validate on 102 samples\n",
-      "Epoch 1/75\n",
-      "404/404 [==============================] - 2s 4ms/sample - loss: 498.2045 - mse: 498.2046 - mae: 20.2543 - val_loss: 421.5039 - val_mse: 421.5038 - val_mae: 18.3349\n",
-      "Epoch 2/75\n",
-      "404/404 [==============================] - 0s 347us/sample - loss: 249.6985 - mse: 249.6985 - mae: 13.2672 - val_loss: 111.3743 - val_mse: 111.3743 - val_mae: 8.6210\n",
-      "Epoch 3/75\n",
-      "404/404 [==============================] - 0s 344us/sample - loss: 56.6755 - mse: 56.6755 - mae: 5.4817 - val_loss: 39.1997 - val_mse: 39.1997 - val_mae: 4.9872\n",
-      "Epoch 4/75\n",
-      "404/404 [==============================] - 0s 364us/sample - loss: 28.3243 - mse: 28.3243 - mae: 3.7054 - val_loss: 26.9866 - val_mse: 26.9866 - val_mae: 4.0796\n",
-      "Epoch 5/75\n",
-      "404/404 [==============================] - 0s 382us/sample - loss: 20.5281 - mse: 20.5281 - mae: 3.1209 - val_loss: 24.6172 - val_mse: 24.6172 - val_mae: 3.8052\n",
-      "Epoch 6/75\n",
-      "404/404 [==============================] - 0s 393us/sample - loss: 17.9283 - mse: 17.9283 - mae: 2.8665 - val_loss: 23.6524 - val_mse: 23.6524 - val_mae: 3.6746\n",
-      "Epoch 7/75\n",
-      "404/404 [==============================] - 0s 440us/sample - loss: 16.9179 - mse: 16.9179 - mae: 2.8781 - val_loss: 23.4620 - val_mse: 23.4620 - val_mae: 3.5778\n",
-      "Epoch 8/75\n",
-      "404/404 [==============================] - 0s 366us/sample - loss: 15.1579 - mse: 15.1579 - mae: 2.6440 - val_loss: 24.1374 - val_mse: 24.1374 - val_mae: 3.5929\n",
-      "Epoch 9/75\n",
-      "404/404 [==============================] - 0s 367us/sample - loss: 14.1717 - mse: 14.1717 - mae: 2.5937 - val_loss: 24.4829 - val_mse: 24.4829 - val_mae: 3.5639\n",
-      "Epoch 10/75\n",
-      "404/404 [==============================] - 0s 359us/sample - loss: 13.5002 - mse: 13.5002 - mae: 2.5633 - val_loss: 25.0170 - val_mse: 25.0170 - val_mae: 3.5601\n",
-      "Epoch 11/75\n",
-      "404/404 [==============================] - 0s 363us/sample - loss: 12.8641 - mse: 12.8641 - mae: 2.4963 - val_loss: 25.1162 - val_mse: 25.1162 - val_mae: 3.5449\n",
-      "Epoch 12/75\n",
-      "404/404 [==============================] - 0s 351us/sample - loss: 12.4033 - mse: 12.4033 - mae: 2.5224 - val_loss: 25.0382 - val_mse: 25.0382 - val_mae: 3.4858\n",
-      "Epoch 13/75\n",
-      "404/404 [==============================] - 0s 363us/sample - loss: 12.2653 - mse: 12.2653 - mae: 2.4637 - val_loss: 26.7274 - val_mse: 26.7274 - val_mae: 3.6054\n",
-      "Epoch 14/75\n",
-      "404/404 [==============================] - 0s 368us/sample - loss: 11.8249 - mse: 11.8249 - mae: 2.4648 - val_loss: 25.2347 - val_mse: 25.2347 - val_mae: 3.4602\n",
-      "Epoch 15/75\n",
-      "404/404 [==============================] - 0s 356us/sample - loss: 11.3965 - mse: 11.3965 - mae: 2.4134 - val_loss: 25.3070 - val_mse: 25.3070 - val_mae: 3.4305\n",
-      "Epoch 16/75\n",
-      "404/404 [==============================] - 0s 363us/sample - loss: 11.0982 - mse: 11.0982 - mae: 2.3616 - val_loss: 25.0599 - val_mse: 25.0599 - val_mae: 3.3784\n",
-      "Epoch 17/75\n",
-      "404/404 [==============================] - 0s 365us/sample - loss: 11.1969 - mse: 11.1969 - mae: 2.3806 - val_loss: 25.1976 - val_mse: 25.1976 - val_mae: 3.3732\n",
-      "Epoch 18/75\n",
-      "404/404 [==============================] - 0s 369us/sample - loss: 10.9278 - mse: 10.9278 - mae: 2.3653 - val_loss: 24.2875 - val_mse: 24.2875 - val_mae: 3.3114\n",
-      "Epoch 19/75\n",
-      "404/404 [==============================] - 0s 365us/sample - loss: 10.5854 - mse: 10.5854 - mae: 2.3170 - val_loss: 26.1450 - val_mse: 26.1450 - val_mae: 3.3971\n",
-      "Epoch 20/75\n",
-      "404/404 [==============================] - 0s 401us/sample - loss: 10.2546 - mse: 10.2546 - mae: 2.2813 - val_loss: 26.5278 - val_mse: 26.5278 - val_mae: 3.4465\n",
-      "Epoch 21/75\n",
-      "404/404 [==============================] - 0s 380us/sample - loss: 10.1321 - mse: 10.1321 - mae: 2.2866 - val_loss: 24.0363 - val_mse: 24.0363 - val_mae: 3.2792\n",
-      "Epoch 22/75\n",
-      "404/404 [==============================] - 0s 421us/sample - loss: 9.9169 - mse: 9.9169 - mae: 2.2907 - val_loss: 23.7310 - val_mse: 23.7310 - val_mae: 3.2334\n",
-      "Epoch 23/75\n",
-      "404/404 [==============================] - 0s 361us/sample - loss: 9.6588 - mse: 9.6588 - mae: 2.2284 - val_loss: 23.6472 - val_mse: 23.6472 - val_mae: 3.2013\n",
-      "Epoch 24/75\n",
-      "404/404 [==============================] - 0s 363us/sample - loss: 9.6887 - mse: 9.6887 - mae: 2.2468 - val_loss: 23.5379 - val_mse: 23.5379 - val_mae: 3.1921\n",
-      "Epoch 25/75\n",
-      "404/404 [==============================] - 0s 373us/sample - loss: 9.4049 - mse: 9.4049 - mae: 2.1999 - val_loss: 23.7713 - val_mse: 23.7713 - val_mae: 3.2273\n",
-      "Epoch 26/75\n",
-      "404/404 [==============================] - 0s 359us/sample - loss: 9.2304 - mse: 9.2304 - mae: 2.1946 - val_loss: 23.5093 - val_mse: 23.5093 - val_mae: 3.2072\n",
-      "Epoch 27/75\n",
-      "404/404 [==============================] - 0s 361us/sample - loss: 9.0493 - mse: 9.0493 - mae: 2.1528 - val_loss: 23.7969 - val_mse: 23.7969 - val_mae: 3.2005\n",
-      "Epoch 28/75\n",
-      "404/404 [==============================] - 0s 359us/sample - loss: 8.9363 - mse: 8.9363 - mae: 2.1475 - val_loss: 22.1030 - val_mse: 22.1030 - val_mae: 3.0707\n",
-      "Epoch 29/75\n",
-      "404/404 [==============================] - 0s 373us/sample - loss: 8.7834 - mse: 8.7834 - mae: 2.1231 - val_loss: 22.5153 - val_mse: 22.5153 - val_mae: 3.1532\n",
-      "Epoch 30/75\n",
-      "404/404 [==============================] - 0s 371us/sample - loss: 8.7925 - mse: 8.7925 - mae: 2.1531 - val_loss: 22.0449 - val_mse: 22.0449 - val_mae: 3.1245\n",
-      "Epoch 31/75\n",
-      "404/404 [==============================] - 0s 374us/sample - loss: 9.1879 - mse: 9.1879 - mae: 2.2029 - val_loss: 22.1780 - val_mse: 22.1780 - val_mae: 3.0623\n",
-      "Epoch 32/75\n",
-      "404/404 [==============================] - 0s 361us/sample - loss: 8.7136 - mse: 8.7136 - mae: 2.1164 - val_loss: 21.9815 - val_mse: 21.9815 - val_mae: 3.0969\n",
-      "Epoch 33/75\n",
-      "404/404 [==============================] - 0s 371us/sample - loss: 8.3018 - mse: 8.3018 - mae: 2.0639 - val_loss: 21.0477 - val_mse: 21.0477 - val_mae: 2.9645\n",
-      "Epoch 34/75\n",
-      "404/404 [==============================] - 0s 362us/sample - loss: 8.4156 - mse: 8.4156 - mae: 2.0970 - val_loss: 22.6659 - val_mse: 22.6659 - val_mae: 3.1235\n",
-      "Epoch 35/75\n",
-      "404/404 [==============================] - 0s 350us/sample - loss: 8.2938 - mse: 8.2938 - mae: 2.0567 - val_loss: 20.9574 - val_mse: 20.9574 - val_mae: 2.9746\n",
-      "Epoch 36/75\n",
-      "404/404 [==============================] - 0s 357us/sample - loss: 8.0515 - mse: 8.0515 - mae: 2.0591 - val_loss: 23.2063 - val_mse: 23.2063 - val_mae: 3.1980\n",
-      "Epoch 37/75\n",
-      "404/404 [==============================] - 0s 381us/sample - loss: 8.1403 - mse: 8.1403 - mae: 2.0584 - val_loss: 24.5238 - val_mse: 24.5237 - val_mae: 3.3531\n",
-      "Epoch 38/75\n",
-      "404/404 [==============================] - 0s 356us/sample - loss: 8.0043 - mse: 8.0043 - mae: 2.0776 - val_loss: 22.5424 - val_mse: 22.5424 - val_mae: 3.1494\n",
-      "Epoch 39/75\n",
-      "404/404 [==============================] - 0s 361us/sample - loss: 8.1182 - mse: 8.1182 - mae: 2.0683 - val_loss: 19.7576 - val_mse: 19.7576 - val_mae: 2.8799\n",
-      "Epoch 40/75\n",
-      "404/404 [==============================] - 0s 374us/sample - loss: 7.8578 - mse: 7.8578 - mae: 2.0131 - val_loss: 20.7728 - val_mse: 20.7728 - val_mae: 2.9499\n",
-      "Epoch 41/75\n",
-      "404/404 [==============================] - 0s 382us/sample - loss: 7.5711 - mse: 7.5711 - mae: 1.9896 - val_loss: 20.6170 - val_mse: 20.6170 - val_mae: 2.9936\n",
-      "Epoch 42/75\n",
-      "404/404 [==============================] - 0s 385us/sample - loss: 7.5822 - mse: 7.5822 - mae: 1.9683 - val_loss: 20.8541 - val_mse: 20.8541 - val_mae: 3.0054\n",
-      "Epoch 43/75\n",
-      "404/404 [==============================] - 0s 408us/sample - loss: 7.4533 - mse: 7.4533 - mae: 1.9645 - val_loss: 20.4473 - val_mse: 20.4473 - val_mae: 2.8861\n",
-      "Epoch 44/75\n",
-      "404/404 [==============================] - 0s 396us/sample - loss: 7.5226 - mse: 7.5226 - mae: 1.9509 - val_loss: 20.5193 - val_mse: 20.5193 - val_mae: 2.9619\n",
-      "Epoch 45/75\n",
-      "404/404 [==============================] - 0s 355us/sample - loss: 7.2819 - mse: 7.2819 - mae: 1.9350 - val_loss: 21.4862 - val_mse: 21.4862 - val_mae: 2.9908\n",
-      "Epoch 46/75\n",
-      "404/404 [==============================] - 0s 354us/sample - loss: 7.0130 - mse: 7.0130 - mae: 1.9152 - val_loss: 20.1577 - val_mse: 20.1577 - val_mae: 2.9370\n",
-      "Epoch 47/75\n",
-      "404/404 [==============================] - 0s 375us/sample - loss: 6.9431 - mse: 6.9431 - mae: 1.8819 - val_loss: 21.1210 - val_mse: 21.1210 - val_mae: 2.9746\n",
-      "Epoch 48/75\n",
-      "404/404 [==============================] - 0s 371us/sample - loss: 6.8982 - mse: 6.8982 - mae: 1.9037 - val_loss: 19.2999 - val_mse: 19.2999 - val_mae: 2.8638\n",
-      "Epoch 49/75\n",
-      "404/404 [==============================] - 0s 368us/sample - loss: 6.9521 - mse: 6.9521 - mae: 1.8862 - val_loss: 20.7825 - val_mse: 20.7825 - val_mae: 2.9369\n",
-      "Epoch 50/75\n",
-      "404/404 [==============================] - 0s 356us/sample - loss: 6.8718 - mse: 6.8718 - mae: 1.8889 - val_loss: 20.0288 - val_mse: 20.0288 - val_mae: 2.8915\n",
-      "Epoch 51/75\n",
-      "404/404 [==============================] - 0s 354us/sample - loss: 6.7111 - mse: 6.7111 - mae: 1.8702 - val_loss: 20.4913 - val_mse: 20.4913 - val_mae: 3.0116\n",
-      "Epoch 52/75\n",
-      "404/404 [==============================] - 0s 361us/sample - loss: 6.7492 - mse: 6.7492 - mae: 1.8482 - val_loss: 18.3008 - val_mse: 18.3008 - val_mae: 2.7362\n",
-      "Epoch 53/75\n",
-      "404/404 [==============================] - 0s 356us/sample - loss: 6.6262 - mse: 6.6262 - mae: 1.8395 - val_loss: 18.1885 - val_mse: 18.1885 - val_mae: 2.6920\n",
-      "Epoch 54/75\n",
-      "404/404 [==============================] - 0s 369us/sample - loss: 6.7148 - mse: 6.7148 - mae: 1.8611 - val_loss: 18.5764 - val_mse: 18.5764 - val_mae: 2.6977\n",
-      "Epoch 55/75\n",
-      "404/404 [==============================] - 0s 358us/sample - loss: 6.5425 - mse: 6.5425 - mae: 1.8522 - val_loss: 19.5772 - val_mse: 19.5772 - val_mae: 2.8326\n",
-      "Epoch 56/75\n",
-      "404/404 [==============================] - 0s 423us/sample - loss: 6.3349 - mse: 6.3349 - mae: 1.8175 - val_loss: 19.0932 - val_mse: 19.0932 - val_mae: 2.8260\n",
-      "Epoch 57/75\n",
-      "404/404 [==============================] - 0s 375us/sample - loss: 6.4253 - mse: 6.4253 - mae: 1.7972 - val_loss: 20.4036 - val_mse: 20.4036 - val_mae: 2.9258\n",
-      "Epoch 58/75\n",
-      "404/404 [==============================] - 0s 362us/sample - loss: 6.2897 - mse: 6.2897 - mae: 1.7785 - val_loss: 21.2845 - val_mse: 21.2845 - val_mae: 3.0715\n",
-      "Epoch 59/75\n",
-      "404/404 [==============================] - 0s 378us/sample - loss: 6.7839 - mse: 6.7839 - mae: 1.9027 - val_loss: 18.6853 - val_mse: 18.6853 - val_mae: 2.7709\n",
-      "Epoch 60/75\n",
-      "404/404 [==============================] - 0s 395us/sample - loss: 6.7178 - mse: 6.7178 - mae: 1.8871 - val_loss: 19.5394 - val_mse: 19.5394 - val_mae: 2.8101\n",
-      "Epoch 61/75\n",
-      "404/404 [==============================] - 0s 366us/sample - loss: 6.4152 - mse: 6.4152 - mae: 1.8175 - val_loss: 18.2377 - val_mse: 18.2377 - val_mae: 2.7450\n",
-      "Epoch 62/75\n",
-      "404/404 [==============================] - 0s 384us/sample - loss: 5.9727 - mse: 5.9727 - mae: 1.7630 - val_loss: 19.0252 - val_mse: 19.0252 - val_mae: 2.7960\n",
-      "Epoch 63/75\n",
-      "404/404 [==============================] - 0s 380us/sample - loss: 6.0973 - mse: 6.0973 - mae: 1.8071 - val_loss: 18.8069 - val_mse: 18.8069 - val_mae: 2.8894\n",
-      "Epoch 64/75\n",
-      "404/404 [==============================] - 0s 362us/sample - loss: 6.1074 - mse: 6.1074 - mae: 1.7978 - val_loss: 18.4702 - val_mse: 18.4702 - val_mae: 2.7851\n",
-      "Epoch 65/75\n",
-      "404/404 [==============================] - 0s 369us/sample - loss: 5.9329 - mse: 5.9329 - mae: 1.7545 - val_loss: 18.5321 - val_mse: 18.5321 - val_mae: 2.7933\n",
-      "Epoch 66/75\n",
-      "404/404 [==============================] - 0s 341us/sample - loss: 5.7473 - mse: 5.7473 - mae: 1.7211 - val_loss: 18.5536 - val_mse: 18.5536 - val_mae: 2.8010\n",
-      "Epoch 67/75\n",
-      "404/404 [==============================] - 0s 339us/sample - loss: 5.8866 - mse: 5.8866 - mae: 1.7224 - val_loss: 18.0067 - val_mse: 18.0067 - val_mae: 2.7054\n",
-      "Epoch 68/75\n",
-      "404/404 [==============================] - 0s 337us/sample - loss: 5.7885 - mse: 5.7885 - mae: 1.7391 - val_loss: 17.5502 - val_mse: 17.5502 - val_mae: 2.6767\n",
-      "Epoch 69/75\n",
-      "404/404 [==============================] - 0s 331us/sample - loss: 5.8809 - mse: 5.8809 - mae: 1.7542 - val_loss: 17.0280 - val_mse: 17.0280 - val_mae: 2.6404\n",
-      "Epoch 70/75\n",
-      "404/404 [==============================] - 0s 343us/sample - loss: 5.6028 - mse: 5.6028 - mae: 1.6972 - val_loss: 17.7188 - val_mse: 17.7188 - val_mae: 2.6979\n",
-      "Epoch 71/75\n",
-      "404/404 [==============================] - 0s 337us/sample - loss: 5.4361 - mse: 5.4361 - mae: 1.6741 - val_loss: 16.8852 - val_mse: 16.8852 - val_mae: 2.6126\n",
-      "Epoch 72/75\n",
-      "404/404 [==============================] - 0s 345us/sample - loss: 5.5608 - mse: 5.5608 - mae: 1.7252 - val_loss: 16.7483 - val_mse: 16.7483 - val_mae: 2.6063\n",
-      "Epoch 73/75\n",
-      "404/404 [==============================] - 0s 341us/sample - loss: 5.5022 - mse: 5.5022 - mae: 1.6912 - val_loss: 17.6786 - val_mse: 17.6786 - val_mae: 2.7316\n",
-      "Epoch 74/75\n",
-      "404/404 [==============================] - 0s 396us/sample - loss: 5.2794 - mse: 5.2794 - mae: 1.6478 - val_loss: 17.6115 - val_mse: 17.6115 - val_mae: 2.6773\n",
-      "Epoch 75/75\n",
-      "404/404 [==============================] - 0s 338us/sample - loss: 5.4796 - mse: 5.4796 - mae: 1.6876 - val_loss: 17.2835 - val_mse: 17.2835 - val_mae: 2.7126\n"
+      "WARNING: Logging before flag parsing goes to stderr.\n",
+      "W0123 13:31:56.599683 29748 deprecation.py:506] From C:\\ProgramData\\Anaconda3\\envs\\U4-S2-NNF\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
+      "Instructions for updating:\n",
+      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
      ]
     },
     {
-     "data": {
-      "text/plain": [
-       "<tensorflow.python.keras.callbacks.History at 0x7f36340c6b38>"
-      ]
-     },
-     "execution_count": 3,
-     "metadata": {},
-     "output_type": "execute_result"
+     "ename": "TypeError",
+     "evalue": "'NoneType' object is not iterable",
+     "output_type": "error",
+     "traceback": [
+      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
+      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
+      "\u001b[1;32m<ipython-input-6-ca2a1412e3bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m          )\n",
+      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\U4-S2-NNF\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m   def evaluate(self,\n",
+      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\U4-S2-NNF\\lib\\site-packages\\wandb\\keras\\__init__.py\u001b[0m in \u001b[0;36mnew_arrays\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[1;31m# TODO: these could be generators, why index 0?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mval_inputs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mval_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mval_inputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_targets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
+      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
+     ]
     }
    ],
    "source": [
@@ -449,7 +305,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 4,
+   "execution_count": 7,
    "metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
@@ -464,21 +320,24 @@
      "name": "stderr",
      "output_type": "stream",
      "text": [
-      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
-      "  warnings.warn(CV_WARNING, FutureWarning)\n"
+      "W0123 13:32:41.029052 29748 deprecation.py:323] From C:\\ProgramData\\Anaconda3\\envs\\U4-S2-NNF\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
+      "Instructions for updating:\n",
+      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
+      "C:\\ProgramData\\Anaconda3\\envs\\U4-S2-NNF\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
+      "  DeprecationWarning)\n"
      ]
     },
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Best: 0.65234375 using {'batch_size': 10, 'epochs': 20}\n",
-      "Means: 0.65234375, Stdev: 0.033298728782667764 with: {'batch_size': 10, 'epochs': 20}\n",
-      "Means: 0.6263020833333334, Stdev: 0.01813592223591682 with: {'batch_size': 20, 'epochs': 20}\n",
-      "Means: 0.6041666666666666, Stdev: 0.037782859709757574 with: {'batch_size': 40, 'epochs': 20}\n",
-      "Means: 0.5533854166666666, Stdev: 0.03210632293213009 with: {'batch_size': 60, 'epochs': 20}\n",
-      "Means: 0.61328125, Stdev: 0.024079742199097563 with: {'batch_size': 80, 'epochs': 20}\n",
-      "Means: 0.5611979166666666, Stdev: 0.038450060052691144 with: {'batch_size': 100, 'epochs': 20}\n"
+      "Best: 0.6432291716337204 using {'batch_size': 10, 'epochs': 20}\n",
+      "Means: 0.6432291716337204, Stdev: 0.03941603227192391 with: {'batch_size': 10, 'epochs': 20}\n",
+      "Means: 0.6250000174622983, Stdev: 0.05886315831701945 with: {'batch_size': 20, 'epochs': 20}\n",
+      "Means: 0.6250000071401397, Stdev: 0.04223050711440435 with: {'batch_size': 40, 'epochs': 20}\n",
+      "Means: 0.6432291700039059, Stdev: 0.06799620666076475 with: {'batch_size': 60, 'epochs': 20}\n",
+      "Means: 0.5989583501747499, Stdev: 0.08078131472004026 with: {'batch_size': 80, 'epochs': 20}\n",
+      "Means: 0.5494791712456694, Stdev: 0.048239581804148994 with: {'batch_size': 100, 'epochs': 20}\n"
      ]
     }
    ],
@@ -525,7 +384,7 @@
     "              'epochs': [20]}\n",
     "\n",
     "# Create Grid Search\n",
-    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
+    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, n_jobs=1)\n",
     "grid_result = grid.fit(X, Y)\n",
     "\n",
     "# Report Results\n",
@@ -551,7 +410,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 5,
+   "execution_count": null,
    "metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
@@ -561,22 +420,10 @@
     "id": "bAmxP3N7TmFh",
     "outputId": "3ddb08c4-51ac-4eaa-ff39-143397024544"
    },
-   "outputs": [
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "Best: 0.7044270833333334 using {'batch_size': 20, 'epochs': 200}\n",
-      "Means: 0.6666666666666666, Stdev: 0.028940248399600087 with: {'batch_size': 20, 'epochs': 20}\n",
-      "Means: 0.6588541666666666, Stdev: 0.028940248399600087 with: {'batch_size': 20, 'epochs': 40}\n",
-      "Means: 0.6848958333333334, Stdev: 0.03498705427745938 with: {'batch_size': 20, 'epochs': 60}\n",
-      "Means: 0.7044270833333334, Stdev: 0.018414239093399672 with: {'batch_size': 20, 'epochs': 200}\n"
-     ]
-    }
-   ],
+   "outputs": [],
    "source": [
     "# define the grid search parameters\n",
-    "param_grid = {'batch_size': [20],\n",
+    "param_grid = {'batch_size': [10],\n",
     "              'epochs': [20, 40, 60,200]}\n",
     "\n",
     "# Create Grid Search\n",
@@ -730,39 +577,32 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 6,
+   "execution_count": 2,
    "metadata": {},
    "outputs": [
     {
-     "data": {
-      "text/html": [
-       "\n",
-       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
-       "                Project page: <a href=\"https://app.wandb.ai/lambda-ds7/boston\" target=\"_blank\">https://app.wandb.ai/lambda-ds7/boston</a><br/>\n",
-       "                Run page: <a href=\"https://app.wandb.ai/lambda-ds7/boston/runs/whw09rro\" target=\"_blank\">https://app.wandb.ai/lambda-ds7/boston/runs/whw09rro</a><br/>\n",
-       "            "
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: WARNING import wandb.keras called before import keras or import tensorflow.keras.  This can lead to a version mismatch, W&B now assumes tensorflow.keras\n"
+     ]
     },
     {
-     "data": {
-      "text/plain": [
-       "W&B Run: https://app.wandb.ai/lambda-ds7/boston/runs/whw09rro"
-      ]
-     },
-     "execution_count": 6,
-     "metadata": {},
-     "output_type": "execute_result"
+     "ename": "NameError",
+     "evalue": "name 'wand' is not defined",
+     "output_type": "error",
+     "traceback": [
+      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
+      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
+      "\u001b[1;32m<ipython-input-2-f029323d4a7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwandb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mwandb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWandbCallback\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mwand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ds9-boston\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ds8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
+      "\u001b[1;31mNameError\u001b[0m: name 'wand' is not defined"
+     ]
     }
    ],
    "source": [
     "import wandb\n",
-    "from wandb.keras import WandbCallback"
+    "from wandb.keras import WandbCallback\n",
+    "wand.init(project=\"ds9-boston\", entity=\"ds8\")"
    ]
   },
   {
@@ -1153,9 +993,9 @@
  ],
  "metadata": {
   "kernelspec": {
-   "display_name": "conda_tensorflow_p36",
+   "display_name": "U4-S2-NNF",
    "language": "python",
-   "name": "conda_tensorflow_p36"
+   "name": "u4-s2-nnf"
   },
   "language_info": {
    "codemirror_mode": {
@@ -1167,7 +1007,7 @@
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
-   "version": "3.6.5"
+   "version": "3.7.0"
   }
  },
  "nbformat": 4,
